{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from os.path import join as pj\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import scipy.sparse as sparse\n",
    "import torch\n",
    "from sae_lens import SAE, ActivationsStore\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from sae_cooccurrence.normalised_cooc_functions import (\n",
    "    create_results_dir,\n",
    ")\n",
    "from sae_cooccurrence.pca import (\n",
    "    analyze_representative_points,\n",
    "    analyze_specific_points,\n",
    "    create_pca_plots_decoder,\n",
    "    generate_data,\n",
    "    generate_subgraph_plot_data_sparse,\n",
    "    get_point_result,\n",
    "    load_data_from_pickle,\n",
    "    perform_pca_on_results,\n",
    "    plot_doubly_clustered_activation_heatmap,\n",
    "    plot_feature_activations,\n",
    "    plot_pca_explanation_and_save,\n",
    "    plot_pca_feature_strength,\n",
    "    plot_pca_single_feature_strength,\n",
    "    plot_pca_with_active_features,\n",
    "    plot_pca_with_top_feature,\n",
    "    plot_simple_scatter,\n",
    "    plot_subgraph_static_from_nx,\n",
    "    plot_token_pca_and_save,\n",
    "    save_data_to_pickle,\n",
    ")\n",
    "from sae_cooccurrence.utils.saving_loading import load_npz_files, set_device\n",
    "from sae_cooccurrence.utils.set_paths import get_git_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging(log_path):\n",
    "    logging.basicConfig(\n",
    "        filename=log_path,\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "# Config -------------\n",
    "torch.set_grad_enabled(False)\n",
    "device = set_device()\n",
    "git_root = get_git_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True\n",
    "\n",
    "\n",
    "model_name = \"gpt2-small\"\n",
    "sae_release_short = \"res-jb\"\n",
    "sae_id = \"blocks.0.hook_resid_pre\"\n",
    "n_batches_reconstruction = 100\n",
    "\n",
    "\n",
    "activation_threshold = 1.5\n",
    "subgraph_id = 3240\n",
    "n_batches_generation = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "fs_splitting_cluster = subgraph_id\n",
    "pca_prefix = \"pca\"\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "# n_batches_reconstruction = config['pca']['n_batches_reconstruction']\n",
    "\n",
    "\n",
    "# Load model\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "# Process the specific subgraph\n",
    "sae_id_neat = sae_id.replace(\".\", \"_\")\n",
    "results_dir = create_results_dir(\n",
    "    model_name, sae_release_short, sae_id_neat, n_batches_generation\n",
    ")\n",
    "results_path = pj(git_root, results_dir)\n",
    "activation_threshold_safe = str(activation_threshold).replace(\".\", \"_\")\n",
    "\n",
    "figures_path = pj(git_root, f\"figures/{model_name}/{sae_release_short}/{sae_id_neat}\")\n",
    "pca_dir = f\"{pca_prefix}_{activation_threshold_safe}_subgraph_{subgraph_id}\"\n",
    "pca_path = pj(figures_path, pca_dir)\n",
    "if not os.path.exists(pca_path):\n",
    "    os.makedirs(pca_path)\n",
    "pickle_file = pj(pca_path, f\"pca_data_subgraph_{subgraph_id}.pkl\")\n",
    "\n",
    "# Set up logging\n",
    "log_path = pj(pca_path, \"pca_analysis.log\")\n",
    "setup_logging(log_path)\n",
    "\n",
    "# Log all settings\n",
    "logging.info(\"Script started\")\n",
    "logging.info(\"Settings:\")\n",
    "logging.info(f\"  save_figs: {save_figs}\")\n",
    "logging.info(f\"  git_root: {git_root}\")\n",
    "logging.info(f\"  sae_id: {sae_id}\")\n",
    "logging.info(f\"  activation_threshold: {activation_threshold}\")\n",
    "logging.info(f\"  subgraph_id: {subgraph_id}\")\n",
    "logging.info(f\"  fs_splitting_cluster: {fs_splitting_cluster}\")\n",
    "logging.info(f\"  pca_prefix: {pca_prefix}\")\n",
    "logging.info(f\"  model_name: {model_name}\")\n",
    "logging.info(f\"  sae_release_short: {sae_release_short}\")\n",
    "logging.info(f\"  n_batches_reconstruction: {n_batches_reconstruction}\")\n",
    "logging.info(f\"  device: {device}\")\n",
    "logging.info(f\"  results_path: {results_path}\")\n",
    "logging.info(f\"  pca_path: {pca_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0631490d014b358f2aa16ab630c52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading npz files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_df = pd.read_csv(\n",
    "    pj(results_path, f\"dataframes/node_info_df_{activation_threshold_safe}.csv\")\n",
    ")\n",
    "logging.info(\n",
    "    f\"Loaded node_df from {pj(results_path, f'dataframes/node_info_df_{activation_threshold_safe}.csv')}\"\n",
    ")\n",
    "\n",
    "overall_feature_activations = load_npz_files(\n",
    "    results_path, \"feature_acts_cooc_activations\"\n",
    ").get(activation_threshold)\n",
    "\n",
    "# with open(pj(results_path, f\"subgraph_objects/activation_{activation_threshold_safe}/subgraph_{subgraph_id}.pkl\"), 'rb') as f:\n",
    "#     subgraph = pickle.load(f)\n",
    "\n",
    "\n",
    "# Filter for the specific subgraph\n",
    "fs_splitting_nodes = node_df.query(\"subgraph_id == @subgraph_id\")[\"node_id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "regen_data = False\n",
    "if not regen_data:\n",
    "    raise ValueError(\"Are you sure you don't want to use existing data?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cc38c9614444d3a6de9b8642e8230f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples found: 165\n"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"PCA analysis script\")\n",
    "# parser.add_argument('--save_pickle', action='store_true', help='Save generated data to pickle')\n",
    "# parser.add_argument('--load_pickle', action='store_true', help='Load data from pickle instead of regenerating')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "if not regen_data and os.path.exists(pickle_file):\n",
    "    data = load_data_from_pickle(pickle_file)\n",
    "    results = data[\"results\"]\n",
    "    pca_df = data[\"pca_df\"]\n",
    "    pca = data[\"pca\"]\n",
    "    pca_decoder = data[\"pca_decoder\"]\n",
    "    pca_decoder_df = data[\"pca_decoder_df\"]\n",
    "else:\n",
    "    # Load SAE and set up activation store\n",
    "    sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release=f\"{model_name}-{sae_release_short}\", sae_id=sae_id, device=device\n",
    "    )\n",
    "    sae.fold_W_dec_norm()\n",
    "\n",
    "    activation_store = ActivationsStore.from_sae(\n",
    "        model=model,\n",
    "        sae=sae,\n",
    "        streaming=True,\n",
    "        store_batch_size_prompts=8,\n",
    "        train_batch_size_tokens=4096,\n",
    "        n_batches_in_buffer=32,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    data = generate_data(\n",
    "        model,\n",
    "        sae,\n",
    "        activation_store,\n",
    "        fs_splitting_nodes,\n",
    "        n_batches_reconstruction,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if regen_data:\n",
    "        save_data_to_pickle(data, pickle_file)\n",
    "\n",
    "    results = data[\"results\"]\n",
    "    pca_df = data[\"pca_df\"]\n",
    "    pca = data[\"pca\"]\n",
    "    pca_decoder = data[\"pca_decoder\"]\n",
    "    pca_decoder_df = data[\"pca_decoder_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_pca_and_save(pca_df, pca_path, subgraph_id, color_by=\"token\", save=save_figs)\n",
    "\n",
    "plot_pca_explanation_and_save(pca, pca_path, subgraph_id, save=save_figs)\n",
    "\n",
    "plot_simple_scatter(results, pca_path, subgraph_id, fs_splitting_nodes, save=save_figs)\n",
    "\n",
    "# pca_decoder, pca_decoder_df = calculate_pca_decoder(sae, fs_splitting_nodes)\n",
    "\n",
    "# Save pca_decoder_df as CSV\n",
    "pca_decoder_df_filename = f\"pca_decoder_df_subgraph_{subgraph_id}.csv\"\n",
    "pca_decoder_df.to_csv(pj(pca_path, pca_decoder_df_filename), index=False)\n",
    "\n",
    "create_pca_plots_decoder(pca_decoder_df, subgraph_id, pca_path, save=save_figs)\n",
    "\n",
    "print(f\"Processing completed for subgraph ID {subgraph_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_with_top_feature(\n",
    "    pca_df, results, fs_splitting_nodes, fs_splitting_cluster, pca_path, save=save_figs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC1\",\n",
    "    pc_y=\"PC2\",\n",
    "    save=save_figs,\n",
    ")\n",
    "plot_pca_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC1\",\n",
    "    pc_y=\"PC3\",\n",
    "    save=save_figs,\n",
    ")\n",
    "plot_pca_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC2\",\n",
    "    pc_y=\"PC3\",\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC2\",\n",
    "    pc_y=\"PC3\",\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_splitting_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_single_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    3266,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC2\",\n",
    "    pc_y=\"PC3\",\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_single_feature_strength(\n",
    "    pca_df,\n",
    "    results,\n",
    "    8838,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    pc_x=\"PC2\",\n",
    "    pc_y=\"PC3\",\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_with_active_features(\n",
    "    pca_df,\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    pca_path,\n",
    "    activation_threshold=activation_threshold,\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_doubly_clustered_activation_heatmap(\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    pca_df,\n",
    "    pca_path,\n",
    "    fs_splitting_cluster,\n",
    "    max_examples=1000,\n",
    "    save=save_figs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_feature_activations_combined(\n",
    "#     get_point_result(results, 2),\n",
    "#     fs_splitting_nodes,\n",
    "#     fs_splitting_cluster,\n",
    "#     activation_threshold,\n",
    "#     node_df,\n",
    "#     results_path,\n",
    "#     pca_path,\n",
    "#     save_figs=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_activations(\n",
    "    get_point_result(results, 2),\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    activation_threshold,\n",
    "    node_df,\n",
    "    results_path,\n",
    "    save_figs=False,\n",
    "    pca_path=pca_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example:\n",
    "pca_df, _ = perform_pca_on_results(results)\n",
    "analyze_representative_points(\n",
    "    results=results,\n",
    "    fs_splitting_nodes=fs_splitting_nodes,\n",
    "    fs_splitting_cluster=fs_splitting_cluster,\n",
    "    activation_threshold=activation_threshold,\n",
    "    node_df=node_df,\n",
    "    results_path=results_path,\n",
    "    pca_df=pca_df,\n",
    "    save_figs=True,\n",
    "    pca_path=pca_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_representative_points_comp(\n",
    "#     results,\n",
    "#     fs_splitting_nodes,\n",
    "#     activation_threshold,\n",
    "#     node_df,\n",
    "#     pca_df,\n",
    "#     save_figs=True,\n",
    "#     pca_path=pca_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After creating the PCA plot and identifying interesting points\n",
    "interesting_point_ids = [54, 357, 178, 930, 1001]  # Replace with actual IDs of interest\n",
    "analyze_specific_points(\n",
    "    results,\n",
    "    fs_splitting_nodes,\n",
    "    fs_splitting_cluster,\n",
    "    activation_threshold,\n",
    "    node_df,\n",
    "    results_path,\n",
    "    pca_df,\n",
    "    interesting_point_ids,\n",
    "    save_figs=True,\n",
    "    pca_path=pca_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_user_specified_points_comp(\n",
    "#     results,\n",
    "#     fs_splitting_nodes,\n",
    "#     activation_threshold,\n",
    "#     node_df,\n",
    "#     pca_df,\n",
    "#     interesting_point_ids,\n",
    "#     save_figs=True,\n",
    "#     pca_path=pca_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze_user_specified_points_comp_subgraph(\n",
    "#     results,\n",
    "#     fs_splitting_nodes,\n",
    "#     fs_splitting_cluster,\n",
    "#     activation_threshold,\n",
    "#     node_df,\n",
    "#     pca_df,\n",
    "#     interesting_point_ids,\n",
    "#     results_path,\n",
    "#     save_figs=True,\n",
    "#     pca_path=pca_path,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_weekdays(\n",
    "    pca_df, pca_path, fs_splitting_cluster, plot_inner=False, save_figs=False\n",
    "):\n",
    "    # Define colors for each day and gray for others\n",
    "    if not plot_inner:\n",
    "        color_map = {\n",
    "            \"Monday\": \"#FF9999\",\n",
    "            \"Tuesday\": \"#66B2FF\",\n",
    "            \"Wednesday\": \"#99FF99\",\n",
    "            \"Thursday\": \"#FFCC99\",\n",
    "            \"Friday\": \"#FF99FF\",\n",
    "            \"Saturday\": \"#99FFFF\",\n",
    "            \"Sunday\": \"#FFFF99\",\n",
    "            \"Other\": \"#CCCCCC\",\n",
    "        }\n",
    "    else:\n",
    "        color_map = {\n",
    "            \"Mon\": \"#FF9999\",\n",
    "            \"Tues\": \"#66B2FF\",\n",
    "            \"Wed\": \"#99FF99\",\n",
    "            \"Thurs\": \"#FFCC99\",\n",
    "            \"Fri\": \"#FF99FF\",\n",
    "            \"Sat\": \"#99FFFF\",\n",
    "            \"Sun\": \"#FFFF99\",\n",
    "            \"Other\": \"#CCCCCC\",\n",
    "        }\n",
    "\n",
    "    # Function to determine color and marker shape\n",
    "    def get_color_and_marker(token):\n",
    "        token_lower = token.lower()\n",
    "        for day in color_map.keys():\n",
    "            if day.lower() in token_lower:\n",
    "                return color_map[day], \"cross\" if \" \" in token else \"circle\"\n",
    "        return color_map[\"Other\"], \"circle\"\n",
    "\n",
    "    # Apply the function to get colors and markers\n",
    "    pca_df[\"color\"], pca_df[\"marker\"] = zip(\n",
    "        *pca_df[\"tokens\"].apply(get_color_and_marker)\n",
    "    )\n",
    "\n",
    "    # Create the plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add traces for colors (days)\n",
    "    for day in list(color_map.keys()):\n",
    "        df_day = pca_df[pca_df[\"color\"] == color_map[day]]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_day[\"PC2\"],\n",
    "                y=df_day[\"PC3\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=color_map[day], size=8),\n",
    "                name=day,\n",
    "                legendgroup=\"days\",\n",
    "                legendgrouptitle_text=\"Day of Week\",\n",
    "                text=[\n",
    "                    f\"Token: {t}<br>Context: {c}\"\n",
    "                    for t, c in zip(df_day[\"tokens\"], df_day[\"context\"])\n",
    "                ],\n",
    "                hoverinfo=\"text\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add traces for shapes (with/without space)\n",
    "    for marker, label in [(\"circle\", \"No Space\"), (\"cross\", \"With Space\")]:\n",
    "        df_marker = pca_df[pca_df[\"marker\"] == marker]\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_marker[\"PC2\"],\n",
    "                y=df_marker[\"PC3\"],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(symbol=marker, size=8, color=\"rgba(0,0,0,0)\"),\n",
    "                name=label,\n",
    "                legendgroup=\"shapes\",\n",
    "                legendgrouptitle_text=\"Token Type\",\n",
    "                text=[\n",
    "                    f\"Token: {t}<br>Context: {c}\"\n",
    "                    for t, c in zip(df_marker[\"tokens\"], df_marker[\"context\"])\n",
    "                ],\n",
    "                hoverinfo=\"text\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=800,\n",
    "        title_text=f\"PCA Analysis - Cluster {fs_splitting_cluster} (Weekdays)\",\n",
    "        xaxis_title=\"PC2\",\n",
    "        yaxis_title=\"PC3\",\n",
    "        legend=dict(groupclick=\"toggleitem\", tracegroupgap=20),\n",
    "    )\n",
    "\n",
    "    fig.update_traces(\n",
    "        marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "        selector=dict(mode=\"markers\"),\n",
    "    )\n",
    "\n",
    "    outer_suffix = \"\" if not plot_inner else \"_inner\"\n",
    "\n",
    "    if save_figs:\n",
    "        # Save as PNG\n",
    "        png_path = os.path.join(\n",
    "            pca_path, f\"pca_plot_weekdays_{fs_splitting_cluster}{outer_suffix}.png\"\n",
    "        )\n",
    "        fig.write_image(png_path, scale=3.0)\n",
    "\n",
    "        # Save as HTML\n",
    "        html_path = os.path.join(\n",
    "            pca_path, f\"pca_plot_weekdays_{fs_splitting_cluster}{outer_suffix}.html\"\n",
    "        )\n",
    "        fig.write_html(html_path)\n",
    "    else:\n",
    "        fig.show()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_weekdays(pca_df, pca_path, fs_splitting_cluster, save_figs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pca_weekdays(\n",
    "    pca_df, pca_path, fs_splitting_cluster, plot_inner=True, save_figs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthew/Documents/Github/sae_cooccurrence/sae_cooccurrence/pca.py:3209: UserWarning:\n",
      "\n",
      "This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subgraph_id = fs_splitting_cluster\n",
    "sparse_thresholded_matrix = sparse.load_npz(\n",
    "    os.path.join(\n",
    "        results_path, \"thresholded_matrices\", \"sparse_thresholded_matrix_1_5.npz\"\n",
    "    ),\n",
    ")\n",
    "subgraph, subgraph_df = generate_subgraph_plot_data_sparse(\n",
    "    sparse_thresholded_matrix=sparse_thresholded_matrix,\n",
    "    node_df=node_df,\n",
    "    subgraph_id=subgraph_id,\n",
    ")\n",
    "plot_subgraph_static_from_nx(\n",
    "    subgraph=subgraph,\n",
    "    output_path=pj(pca_path, \"subgraph_static\"),\n",
    "    subgraph_df=subgraph_df,\n",
    "    node_info_df=node_df,\n",
    "    save_figs=True,\n",
    "    show_plot=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
