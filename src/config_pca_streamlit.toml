[generation]
n_batches = 100

[model]
name = "gemma-2-2b"
# name = "gpt2-small"
sae_release_short = "gemma-scope-2b-pt-res-canonical"
# sae_release_short = "res-jb-feature-splitting"
sae_ids = [
    "layer_21/width_16k/canonical", 
    # "layer_18/width_16k/canonical",
    # "layer_19/width_16k/canonical", 
    # "layer_20/width_16k/canonical",
    # "layer_22/width_16k/canonical"
]

[processing]
remove_special_tokens = true
n_batches_reconstruction = 100
activation_threshold = 1.5
subgraph_sizes_to_plot = [5, 6, 7]
max_examples = 5000
trim_excess = false
save_all_feature_acts = false

[processing.save_options]
fired_tokens = false
top_3_tokens = true
context = true
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false
pca = true

[processing.load_options]
use_max_examples = true
fired_tokens = false
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false

[streamlit.models]
gpt2-small = "gpt2-small"
gemma-2-2b = "gemma-2-2b"

[models.batch_sizes]
gpt2-small = 100
gemma-2-2b = 10

[models.max_examples]
gpt2-small = 1000
gemma-2-2b = 1000

[models.releases]
"gpt2-small" = ["res-jb", "res-jb-feature-splitting"]
"gemma-2-2b" = [
    "gemma-scope-2b-pt-res-canonical",
    "gemma-scope-2b-pt-res"
]

[models.sae_ids]
"res-jb" = ["blocks.0.hook_resid_pre"]
"res-jb-feature-splitting" = ["blocks.8.hook_resid_pre_24576"]
"gemma-scope-2b-pt-res-canonical" = [
    "layer_0/width_16k/canonical",
    "layer_12/width_16k/canonical",
    "layer_12/width_32k/canonical",
    "layer_12/width_65k/canonical",
    "layer_18/width_16k/canonical",
    "layer_21/width_16k/canonical"
]
"gemma-scope-2b-pt-res" = [
    "layer_12/width_16k/average_l0_22",
    "layer_12/width_16k/average_l0_41",
    "layer_12/width_16k/average_l0_82",
    "layer_12/width_16k/average_l0_176",
    "layer_12/width_16k/average_l0_445"
]
