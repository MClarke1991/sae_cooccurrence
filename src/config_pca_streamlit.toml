[model]
# name = "gemma-2-2b"
name = "gpt2-small"
# sae_release_short = "gemma-scope-2b-pt-res-canonical"
sae_release_short = "res-jb-feature-splitting"
sae_ids = [
    "blocks.8.hook_resid_pre_24576",
    # "blocks.0.hook_resid_pre_768",
    # "blocks.8.hook_resid_pre_1536",
    # "blocks.8.hook_resid_pre_3072",
    # "blocks.8.hook_resid_pre_6144",
    # "blocks.8.hook_resid_pre_12288",
]

[processing]
remove_special_tokens = false
n_batches_reconstruction = 10
activation_threshold = 1.5
subgraph_sizes_to_plot = [51]
save_all_feature_acts = false

[processing.save_options]
fired_tokens = false
top_3_tokens = true
context = true
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false
pca = true

[processing.load_options]
fired_tokens = false
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false