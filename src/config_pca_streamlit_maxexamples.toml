[generation]
n_batches_generation = 1000

[model]
# #name = "gemma-2-2b"
# name = "gpt2-small"
# # sae_release_short = "gemma-scope-2b-pt-res-canonical"
# sae_release_short = "res-jb-feature-splitting"
# sae_ids = [
#     "blocks.8.hook_resid_pre_768",
#     "blocks.8.hook_resid_pre_1536",
#     "blocks.8.hook_resid_pre_3072",
#     "blocks.8.hook_resid_pre_6144",
#     "blocks.8.hook_resid_pre_12288",
#     "blocks.8.hook_resid_pre_24576",
#     "blocks.8.hook_resid_pre_49152",
# ]

name = "gpt2-small"
sae_release_short = "res-jb"
sae_ids = ["blocks.0.hook_resid_pre"]


[processing]
remove_special_tokens = false
n_batches_reconstruction = 10000
activation_threshold = 1.5
subgraph_sizes_to_plot = [4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
max_examples = 5000
trim_excess = false
save_all_feature_acts = false

[processing.save_options]
fired_tokens = false
top_3_tokens = true
context = true
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false
pca = true

[processing.load_options]
thresholded_matrix = true
use_max_examples = true
fired_tokens = false
reconstructions = false
graph_feature_acts = true
feature_acts = false
max_feature_info = true
examples_found = false
token_dfs = false

[streamlit]
remove_token_counts = true

[streamlit.models]
gpt2-small = "gpt2-small"
gemma-2-2b = "gemma-2-2b"

[releases.generation_batch_sizes]
res-jb = 1000
res-jb-feature-splitting = 500
gemma-scope-2b-pt-res-canonical = 100
gemma-scope-2b-pt-res = 100

[models.pca_batch_sizes]
gpt2-small = 10000
gemma-2-2b = 100

[models.max_examples]
gpt2-small = 5000
gemma-2-2b = 5000

[models.releases]
"gpt2-small" = ["res-jb", "res-jb-feature-splitting"]
"gemma-2-2b" = [
    "gemma-scope-2b-pt-res-canonical",
    "gemma-scope-2b-pt-res"
]

[models.sae_ids]
"res-jb" = ["blocks.0.hook_resid_pre"]
"res-jb-feature-splitting" = [
    "blocks.8.hook_resid_pre_768",
    "blocks.8.hook_resid_pre_1536",
    "blocks.8.hook_resid_pre_3072",
    "blocks.8.hook_resid_pre_6144",
    "blocks.8.hook_resid_pre_12288",
    "blocks.8.hook_resid_pre_24576"
]
"gemma-scope-2b-pt-res-canonical" = [
    "layer_0/width_16k/canonical",
    "layer_12/width_16k/canonical",
    # "layer_12/width_32k/canonical",
    # "layer_12/width_65k/canonical",
    "layer_18/width_16k/canonical",
    "layer_21/width_16k/canonical"
]
"gemma-scope-2b-pt-res" = [
     "layer_12/width_16k/average_l0_22",
    "layer_12/width_16k/average_l0_41",
    "layer_12/width_16k/average_l0_82",
    "layer_12/width_16k/average_l0_176",
    "layer_12/width_16k/average_l0_445"
]

[streamlit.dev]
show_max_examples = true
show_batch_size = true

[recommended_views.gemma_one_of]
display_name = "Gemma-2-2B: N of"
description = "Latents that compositionally encode number of items referenced"
model = "gemma-2-2b"
sae_release = "gemma-scope-2b-pt-res-canonical"
sae_id = "layer_12_width_16k_canonical"
size = 4
subgraph = 4740

[recommended_views.gpt2_day]
display_name = "GPT2-Small: Day of the week"
description = "Latents sharing properties of days of the week"
model = "gpt2-small"
sae_release = "res-jb"
sae_id = "blocks_8_hook_resid_pre"
size = 8
subgraph = 3240

# [recommended_views.gpt2_month]
# display_name = "GPT2-Small: Month of the year"
# description = "Latents sharing properties of months of the year"
# model = "gpt2-small"
# sae_release = "res-jb"
# sae_id = "blocks_8_hook_resid_pre"
# size = 12
# subgraph = 2644

[recommended_views.gpt2_twitter]
display_name = "GPT2-Small: URL Subdirectory"
description = "Latents that measure position of token within a URL subdirectory"
model = "gpt2-small"
sae_release = "res-jb-feature-splitting"
sae_id = "blocks_8_hook_resid_pre_24576"
size = 5
subgraph = 125

[recommended_views.gpt2_how]
display_name = "GPT2-Small: Disambiguation of 'how'"
description = "Latents disambiguate uses of the word 'how'"
model = "gpt2-small"
sae_release = "res-jb-feature-splitting"
sae_id = "blocks_8_hook_resid_pre_24576"
size = 5
subgraph = 787

[recommended_views.gemma_apostrophe]
display_name = "Gemma-2-2B: Type of possessor"
description = "Latents that disambiguate type of possessor indicated by an apostrophe"
model = "gemma-2-2b"
sae_release = "gemma-scope-2b-pt-res-canonical"
sae_id = "layer_12_width_16k_canonical"
size = 5
subgraph = 4334


