{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from num2words import num2words\n",
    "\n",
    "# from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, ActivationsStore, HookedSAETransformer\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers.utils.logging import disable_progress_bar\n",
    "\n",
    "from sae_cooccurrence.utils.set_paths import get_git_root\n",
    "\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "git_root = get_git_root()\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec8e54dfe0a4319a2dd1a8ede7128d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py:245: UserWarning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gemma-2-2b\", device=device)\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gemma-scope-2b-pt-res-canonical\",  # <- Release name\n",
    "    sae_id=\"layer_12/width_16k/canonical\",  # <- SAE id (not always a hook point!)\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "activation_store = ActivationsStore.from_sae(\n",
    "    model=model,\n",
    "    sae=sae,\n",
    "    streaming=True,\n",
    "    # fairly conservative parameters here so can use same for larger\n",
    "    # models without running out of memory.\n",
    "    store_batch_size_prompts=8,\n",
    "    train_batch_size_tokens=4096,\n",
    "    n_batches_in_buffer=4,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\n",
      "Remember:\n",
      "- For 0, use 'zero' not '0'\n",
      "- The total number of tokens equals the sum of black and white tokens\n",
      "- Always write numbers as words (e.g., 'two' not '2')\n",
      "\n",
      "For example, this is correct: \n",
      "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
      "A: five of them are white\n",
      "\n",
      "Whereas this is incorrect:\n",
      "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
      "A: 5 of them are white\n",
      "\n",
      "Training Questions:\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have seven tokens, and none of them are black. How many of my tokens are white?\n",
      "A: all of them are white\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have nine tokens, and none of them are white. How many of my tokens are black?\n",
      "A: all of them are black\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have nine tokens, and none of them are white. How many of my tokens are black?\n",
      "A: all of them are black\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have seven tokens, and some of them are black. How many of my tokens are white?\n",
      "A: some of them are white\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have ten tokens, and all of them are black. How many of my tokens are white?\n",
      "A: none of them are white\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have nine tokens, and six of them are black. How many of my tokens are white?\n",
      "A: three of them are white\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have eight tokens, and six of them are black. How many of my tokens are white?\n",
      "A: two of them are white\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have six tokens, and five of them are white. How many of my tokens are black?\n",
      "A: one of them are black\n",
      "\n",
      "\n",
      "# Cases with 'some'\n",
      "Q: I have three tokens, and some of them are white. How many of my tokens are black?\n",
      "A: some of them are black\n",
      "\n",
      "\n",
      "# Cases with 'some'\n",
      "Q: I have ten tokens, and all of them are black. How many of my tokens are white?\n",
      "A: none of them are white\n",
      "\n",
      "\n",
      "# Zero cases\n",
      "Q: I have eight tokens, and all of them are white. How many of my tokens are black?\n",
      "A: zero of them are black\n",
      "\n",
      "\n",
      "# Zero cases\n",
      "Q: I have eight tokens, and all of them are black. How many of my tokens are white?\n",
      "A: zero of them are white\n",
      "\n",
      "\n",
      "Test Question:\n",
      "Q: I have ten tokens, and seven of them are white. How many of my tokens are black?\n",
      "\n",
      "Expected Answer:\n",
      "A: three of them are black\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from num2words import num2words\n",
    "\n",
    "\n",
    "class TokenQuestionGenerator:\n",
    "    def __init__(self):\n",
    "        self.colors = [\"black\", \"white\"]\n",
    "        self.special_cases = {\"some\": \"some\", \"all\": \"none\", \"none\": \"all\"}\n",
    "        self.sections = [\"basic\", \"numeric\", \"special\", \"zero\"]\n",
    "\n",
    "    def _number_to_words(self, n: int) -> str:\n",
    "        \"\"\"Convert a number to words.\"\"\"\n",
    "        return num2words(n)\n",
    "\n",
    "    def _questions_are_equivalent(self, q1: str, q2: str) -> bool:\n",
    "        \"\"\"Compare two questions to check if they are functionally equivalent.\"\"\"\n",
    "        # Extract key parts for comparison\n",
    "        q1_parts = [p.lower() for p in q1.split() if p.lower() not in [\"q:\", \"a:\", \"and\", \"are\", \"of\", \"them\", \"my\", \"tokens\", \"have\", \"how\", \"many\"]]\n",
    "        q2_parts = [p.lower() for p in q2.split() if p.lower() not in [\"q:\", \"a:\", \"and\", \"are\", \"of\", \"them\", \"my\", \"tokens\", \"have\", \"how\", \"many\"]]\n",
    "        return q1_parts == q2_parts\n",
    "\n",
    "    def generate_zero_case_question(self) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question where one color has zero tokens.\"\"\"\n",
    "        n_total = random.randint(2, 10)\n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"all of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = f\"A: zero of them are {test_color}\"\n",
    "        return question, answer\n",
    "\n",
    "    def generate_numeric_question(self, force_complementary: bool = False) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question with numeric values.\"\"\"\n",
    "        n_total = random.randint(3, 10)  # Minimum 3 tokens for more interesting cases\n",
    "        if force_complementary:\n",
    "            # Generate numbers that sum to interesting complements\n",
    "            n_color_tokens = random.randint(1, n_total - 1)  # Ensure at least 1 token of each color\n",
    "        else:\n",
    "            n_color_tokens = random.randint(0, n_total)\n",
    "        \n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"{self._number_to_words(n_color_tokens)} of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = f\"A: {self._number_to_words(n_total - n_color_tokens)} of them are {test_color}\"\n",
    "        return question, answer\n",
    "\n",
    "    def generate_special_case_question(self) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question with special quantifiers (some, all, none).\"\"\"\n",
    "        special_type = random.choice(list(self.special_cases.keys()))\n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "        n_total = random.randint(3, 10)\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"{special_type} of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = f\"A: {self.special_cases[special_type]} of them are {test_color}\"\n",
    "        return question, answer\n",
    "\n",
    "    def generate_test_question(self, force_numeric: bool | None = None, force_special: bool | None = None) -> tuple[str, str]:\n",
    "        \"\"\"Generate a test question.\"\"\"\n",
    "        if force_numeric and force_special:\n",
    "            raise ValueError(\"Cannot force both numeric and special case\")\n",
    "\n",
    "        if force_numeric:\n",
    "            return self.generate_numeric_question(force_complementary=True)\n",
    "        elif force_special:\n",
    "            return self.generate_special_case_question()\n",
    "        else:\n",
    "            generators = [\n",
    "                self.generate_numeric_question,\n",
    "                self.generate_special_case_question,\n",
    "                self.generate_zero_case_question\n",
    "            ]\n",
    "            return random.choice(generators)()\n",
    "\n",
    "    def generate_training_set(self, section_counts: dict) -> list[tuple[str, str, str]]:\n",
    "        \"\"\"Generate a structured training set with sections.\"\"\"\n",
    "        training_set = []\n",
    "        \n",
    "        # Basic cases (all/none)\n",
    "        for _ in range(section_counts.get(\"basic\", 0)):\n",
    "            q, a = self.generate_special_case_question()\n",
    "            training_set.append((\"# Basic cases - all/none\", q, a))\n",
    "            \n",
    "        # Numeric cases with specific complementary numbers\n",
    "        for _ in range(section_counts.get(\"numeric\", 0)):\n",
    "            q, a = self.generate_numeric_question(force_complementary=True)\n",
    "            training_set.append((\"# Cases with specific numbers\", q, a))\n",
    "            \n",
    "        # Special cases (some)\n",
    "        for _ in range(section_counts.get(\"special\", 0)):\n",
    "            q, a = self.generate_special_case_question()\n",
    "            training_set.append((\"# Cases with 'some'\", q, a))\n",
    "            \n",
    "        # Zero cases\n",
    "        for _ in range(section_counts.get(\"zero\", 0)):\n",
    "            q, a = self.generate_zero_case_question()\n",
    "            training_set.append((\"# Zero cases\", q, a))\n",
    "            \n",
    "        return training_set\n",
    "\n",
    "def generate_training_and_test(\n",
    "    section_counts: dict = {\n",
    "        \"basic\": 2,    # all/none cases\n",
    "        \"numeric\": 3,  # specific number cases\n",
    "        \"special\": 2,  # 'some' cases\n",
    "        \"zero\": 2      # explicit zero cases\n",
    "    },\n",
    "    force_test_type: str | None = None,\n",
    "    max_attempts: int = 100\n",
    ") -> dict:\n",
    "    \"\"\"Generate a structured training set and test question.\"\"\"\n",
    "    generator = TokenQuestionGenerator()\n",
    "    \n",
    "    # Generate test question\n",
    "    force_numeric = True if force_test_type == \"numeric\" else None\n",
    "    force_special = True if force_test_type == \"special\" else None\n",
    "    test_question, test_answer = generator.generate_test_question(\n",
    "        force_numeric=force_numeric, force_special=force_special\n",
    "    )\n",
    "    \n",
    "    # Generate training set with sections\n",
    "    training_set = []\n",
    "    attempts = 0\n",
    "    \n",
    "    while len(training_set) < sum(section_counts.values()) and attempts < max_attempts:\n",
    "        current_set = generator.generate_training_set(section_counts)\n",
    "        \n",
    "        # Filter out any questions that match the test question\n",
    "        filtered_set = [\n",
    "            (section, q, a)\n",
    "            for section, q, a in current_set\n",
    "            if not generator._questions_are_equivalent(q, test_question)\n",
    "        ]\n",
    "        \n",
    "        if len(filtered_set) == sum(section_counts.values()):\n",
    "            training_set = filtered_set\n",
    "            break\n",
    "            \n",
    "        attempts += 1\n",
    "    \n",
    "    if attempts >= max_attempts:\n",
    "        raise RuntimeError(\"Failed to generate unique training set after maximum attempts\")\n",
    "    \n",
    "    # Format the introduction with explicit instructions\n",
    "    introduction = \"\"\"\n",
    "Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\n",
    "Remember:\n",
    "- For 0, use 'zero' not '0'\n",
    "- The total number of tokens equals the sum of black and white tokens\n",
    "- Always write numbers as words (e.g., 'two' not '2')\n",
    "\n",
    "For example, this is correct: \n",
    "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
    "A: five of them are white\n",
    "\n",
    "Whereas this is incorrect:\n",
    "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
    "A: 5 of them are white\n",
    "\"\"\"\n",
    "    \n",
    "    return {\n",
    "        \"introduction\": introduction.strip(),\n",
    "        \"training_questions\": training_set,\n",
    "        \"test_question\": test_question,\n",
    "        \"test_answer\": test_answer\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Custom section counts\n",
    "    section_counts = {\n",
    "        \"basic\": 5,    # all/none cases\n",
    "        \"numeric\": 3,  # specific number cases\n",
    "        \"special\": 2,  # 'some' cases\n",
    "        \"zero\": 2      # explicit zero cases\n",
    "    }\n",
    "    \n",
    "    result = generate_training_and_test(\n",
    "        section_counts=section_counts,\n",
    "        force_test_type=\"numeric\"  # Can be 'numeric', 'special', or None\n",
    "    )\n",
    "    \n",
    "    print(result[\"introduction\"])\n",
    "    print(\"\\nTraining Questions:\")\n",
    "    for section, q, a in result[\"training_questions\"]:\n",
    "        if section:\n",
    "            print(f\"\\n{section}\")\n",
    "        print(f\"{q}\\n{a}\\n\")\n",
    "    print(\"\\nTest Question:\")\n",
    "    print(result[\"test_question\"])\n",
    "    print(\"\\nExpected Answer:\")\n",
    "    print(result[\"test_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def find_max_activation(model, sae, activation_store, feature_idx, num_batches=100):\n",
    "    \"\"\"\n",
    "    Find the maximum activation for a given feature index. This is useful for\n",
    "    calibrating the right amount of the feature to add.\n",
    "    \"\"\"\n",
    "    max_activation = 0.0\n",
    "\n",
    "    pbar = tqdm(range(num_batches))\n",
    "    for _ in pbar:\n",
    "        tokens = activation_store.get_batch_tokens()\n",
    "\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens,\n",
    "            stop_at_layer=sae.cfg.hook_layer + 1,\n",
    "            names_filter=[sae.cfg.hook_name],\n",
    "        )\n",
    "        sae_in = cache[sae.cfg.hook_name]\n",
    "        feature_acts = sae.encode(sae_in).squeeze()\n",
    "\n",
    "        feature_acts = feature_acts.flatten(0, 1)\n",
    "        batch_max_activation = feature_acts[:, feature_idx].max().item()\n",
    "        max_activation = max(max_activation, batch_max_activation)\n",
    "\n",
    "        pbar.set_description(f\"Max activation: {max_activation:.4f}\")\n",
    "\n",
    "    return max_activation\n",
    "\n",
    "\n",
    "def steering(activations, steering_strength=1.0, steering_vector=None, max_act=1.0):\n",
    "    # Note if the feature fires anyway, we'd be adding to that here.\n",
    "    return activations + max_act * steering_strength * steering_vector\n",
    "\n",
    "\n",
    "def generate_with_steering(\n",
    "    model,\n",
    "    sae,\n",
    "    prompt,\n",
    "    steering_feature,\n",
    "    max_act,\n",
    "    steering_strength=1.0,\n",
    "    max_new_tokens=95,\n",
    "):\n",
    "    input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "\n",
    "    steering_vector = sae.W_dec[steering_feature].to(model.cfg.device)\n",
    "\n",
    "    steering_hook = partial(\n",
    "        steering,\n",
    "        steering_vector=steering_vector,\n",
    "        steering_strength=steering_strength,\n",
    "        max_act=max_act,\n",
    "    )\n",
    "\n",
    "    # standard transformerlens syntax for a hook context for generation\n",
    "    with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            stop_at_eos=False if device == \"mps\" else True,\n",
    "            prepend_bos=sae.cfg.prepend_bos,\n",
    "        )\n",
    "\n",
    "    return model.tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_steering(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    feature_to_steer: int | None = None,\n",
    "    steering_strength: float = 1.0,\n",
    "    max_act: float = 60.0,\n",
    "    n_numeric: int = 10,\n",
    "    n_special: int = 10,\n",
    "    max_new_tokens: int = 5,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Test model accuracy on token counting tasks with optional feature steering.\n",
    "\n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        sae: The sparse autoencoder\n",
    "        feature_to_steer: Feature index to steer, or None for no steering\n",
    "        steering_strength: Strength of steering (default 1.0)\n",
    "        max_act: Maximum activation for the steered feature\n",
    "        n_numeric: Number of numeric test questions\n",
    "        n_special: Number of special test questions\n",
    "        max_new_tokens: Maximum tokens to generate for each answer\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing accuracy metrics and test results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"numeric_correct\": 0,\n",
    "        \"special_correct\": 0,\n",
    "        \"numeric_tests\": [],\n",
    "        \"special_tests\": [],\n",
    "    }\n",
    "\n",
    "    for test_type in [\"numeric\", \"special\"]:\n",
    "        n_tests = n_numeric if test_type == \"numeric\" else n_special\n",
    "        for _ in range(n_tests):\n",
    "            test_data = generate_training_and_test(\n",
    "                num_training_numeric=40,\n",
    "                num_training_special=20,\n",
    "                force_test_type=test_type,\n",
    "            )\n",
    "\n",
    "            prompt = (\n",
    "                test_data[\"introduction\"]\n",
    "                + \"\\n\\n\"\n",
    "                + \"\\n\\n\".join(\n",
    "                    f\"{q}\\n{a}\\n{label}\"\n",
    "                    for q, a, label in test_data[\"training_questions\"]\n",
    "                )\n",
    "                + f\"\\n\\n{test_data['test_question']}\\nA: \"\n",
    "            )\n",
    "\n",
    "            if feature_to_steer is not None:\n",
    "                generated = generate_with_steering(\n",
    "                    model,\n",
    "                    sae,\n",
    "                    prompt,\n",
    "                    feature_to_steer,\n",
    "                    max_act,\n",
    "                    steering_strength=steering_strength,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                )\n",
    "            else:\n",
    "                # Convert prompt to tokens first\n",
    "                input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "                output = model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    # temperature=0.7,\n",
    "                    # top_p=0.9,\n",
    "                    stop_at_eos=False if device == \"mps\" else True,\n",
    "                    prepend_bos=sae.cfg.prepend_bos,\n",
    "                )\n",
    "                generated = model.tokenizer.decode(output[0])\n",
    "\n",
    "            test_result = {\n",
    "                \"prompt\": prompt,\n",
    "                \"expected\": test_data[\"test_answer\"],\n",
    "                \"generated\": generated,\n",
    "                \"correct\": test_data[\"test_answer\"] in generated,\n",
    "            }\n",
    "\n",
    "            if test_type == \"numeric\":\n",
    "                results[\"numeric_tests\"].append(test_result)\n",
    "                if test_result[\"correct\"]:\n",
    "                    results[\"numeric_correct\"] += 1\n",
    "            else:\n",
    "                results[\"special_tests\"].append(test_result)\n",
    "                if test_result[\"correct\"]:\n",
    "                    results[\"special_correct\"] += 1\n",
    "\n",
    "    # Calculate accuracies\n",
    "    results[\"numeric_accuracy\"] = results[\"numeric_correct\"] / n_numeric\n",
    "    results[\"special_accuracy\"] = results[\"special_correct\"] / n_special\n",
    "    results[\"total_accuracy\"] = (\n",
    "        results[\"numeric_correct\"] + results[\"special_correct\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Test without steering\n",
    "#     normal_results = evaluate_model_with_steering(model, sae)\n",
    "#     print(\"\\nResults without steering:\")\n",
    "#     print(f\"Numeric accuracy: {normal_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {normal_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {normal_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results:\")\n",
    "#     for i, test in enumerate(normal_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results:\")\n",
    "#     for i, test in enumerate(normal_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     # Test with feature steering\n",
    "#     feature_to_steer = 12257  # Replace with your feature of interest\n",
    "#     steering_strength = 0.0\n",
    "#     steered_results = evaluate_model_with_steering(\n",
    "#         model,\n",
    "#         sae,\n",
    "#         feature_to_steer=feature_to_steer,\n",
    "#         steering_strength=steering_strength,\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"\\nResults with feature {feature_to_steer} steered (strength {steering_strength}):\"\n",
    "#     )\n",
    "#     print(f\"Numeric accuracy: {steered_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {steered_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {steered_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     # Test with feature steering\n",
    "#     feature_to_steer = 15441  # Replace with your feature of interest\n",
    "#     steering_strength = 0.0\n",
    "#     steered_results = evaluate_model_with_steering(\n",
    "#         model,\n",
    "#         sae,\n",
    "#         feature_to_steer=feature_to_steer,\n",
    "#         steering_strength=steering_strength,\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"\\nResults with feature {feature_to_steer} steered (strength {steering_strength}):\"\n",
    "#     )\n",
    "#     print(f\"Numeric accuracy: {steered_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {steered_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {steered_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_intervention(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    feature_ids: int | list[int] | None = None,\n",
    "    intervention_type: str = \"none\",  # \"none\", \"steering\", or \"ablation\"\n",
    "    steering_strength: float = 1.0,\n",
    "    max_act: float = 60.0,\n",
    "    n_numeric: int = 10,\n",
    "    n_special: int = 10,\n",
    "    max_new_tokens: int = 6,\n",
    "    temperature: float = 0.0,\n",
    "    top_p: float = 0.9,\n",
    "    section_counts: dict | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Test model accuracy on token counting tasks with optional feature steering or ablation.\n",
    "    Lenient scoring now accepts numeric answers for 'all' cases.\n",
    "    \"\"\"\n",
    "    if section_counts is None:\n",
    "        section_counts = {\n",
    "            \"basic\": 2,     # all/none cases\n",
    "            \"numeric\": 3,   # specific number cases\n",
    "            \"special\": 2,   # 'some' cases\n",
    "            \"zero\": 2       # explicit zero cases\n",
    "        }\n",
    "\n",
    "    results = {\n",
    "        \"numeric_correct_strict\": 0,\n",
    "        \"numeric_correct_lenient\": 0,\n",
    "        \"special_correct_strict\": 0,\n",
    "        \"special_correct_lenient\": 0,\n",
    "        \"numeric_tests\": [],\n",
    "        \"special_tests\": [],\n",
    "    }\n",
    "\n",
    "    def convert_words_to_digits(text: str) -> str:\n",
    "        \"\"\"Convert number words to digits in the text.\"\"\"\n",
    "        word_to_digit = {\n",
    "            \"zero\": \"0\",\n",
    "            \"none\": \"0\",\n",
    "            \"one\": \"1\",\n",
    "            \"two\": \"2\",\n",
    "            \"three\": \"3\",\n",
    "            \"four\": \"4\",\n",
    "            \"five\": \"5\",\n",
    "            \"six\": \"6\",\n",
    "            \"seven\": \"7\",\n",
    "            \"eight\": \"8\",\n",
    "            \"nine\": \"9\",\n",
    "            \"ten\": \"10\",\n",
    "        }\n",
    "        for word, digit in word_to_digit.items():\n",
    "            text = text.replace(word, digit)\n",
    "        return text\n",
    "\n",
    "    def check_answer_lenient(generated: str, expected: str, question: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if answer is correct under lenient scoring rules.\n",
    "        \n",
    "        Args:\n",
    "            generated: Generated answer text\n",
    "            expected: Expected answer text\n",
    "            question: Original question text (needed to extract total token count)\n",
    "            \n",
    "        Returns:\n",
    "            bool: Whether the answer is correct under lenient scoring\n",
    "        \"\"\"\n",
    "        # Convert both to lowercase for comparison\n",
    "        generated = generated.lower()\n",
    "        expected = expected.lower()\n",
    "        \n",
    "        # First check if it's an exact match after converting words to digits\n",
    "        generated_digits = convert_words_to_digits(generated)\n",
    "        expected_digits = convert_words_to_digits(expected)\n",
    "        \n",
    "        if expected_digits in generated_digits:\n",
    "            return True\n",
    "            \n",
    "        # Check if this is an \"all of them are\" case\n",
    "        if \"all of them are\" in expected:\n",
    "            # Extract the total number from the question\n",
    "            question_words = question.lower().split()\n",
    "            try:\n",
    "                # Find the word after \"have\" in the question\n",
    "                have_idx = question_words.index(\"have\")\n",
    "                total_tokens = convert_words_to_digits(question_words[have_idx + 1])\n",
    "                \n",
    "                # Check if the generated answer contains this number\n",
    "                # Allow both \"N of them\" and just \"N\"\n",
    "                return (\n",
    "                    total_tokens in generated_digits\n",
    "                    or f\"{total_tokens} of them\" in generated_digits\n",
    "                )\n",
    "            except (ValueError, IndexError):\n",
    "                return False\n",
    "                \n",
    "        return False\n",
    "\n",
    "    # Convert single feature_id to list for consistency\n",
    "    if isinstance(feature_ids, int):\n",
    "        feature_ids = [feature_ids]\n",
    "\n",
    "    def ablate_feature_hook(feature_activations, hook=None, feature_ids=None):  # noqa: ARG001\n",
    "        feature_activations[:, :, feature_ids] = 0\n",
    "        return feature_activations\n",
    "\n",
    "    for test_type in tqdm([\"numeric\", \"special\"], desc=\"Testing types\"):\n",
    "        n_tests = n_numeric if test_type == \"numeric\" else n_special\n",
    "        for _ in tqdm(range(n_tests), desc=f\"Testing {test_type}\"):\n",
    "            # Use new structured prompt generator\n",
    "            test_data = generate_training_and_test(\n",
    "                section_counts=section_counts,\n",
    "                force_test_type=test_type,\n",
    "            )\n",
    "\n",
    "            # Construct prompt with sections\n",
    "            prompt_parts = [test_data[\"introduction\"]]\n",
    "            \n",
    "            # Group questions by section\n",
    "            sections = {}\n",
    "            for section, q, a in test_data[\"training_questions\"]:\n",
    "                if section not in sections:\n",
    "                    sections[section] = []\n",
    "                sections[section].append((q, a))\n",
    "            \n",
    "            # Add each section with its header\n",
    "            for section, questions in sections.items():\n",
    "                prompt_parts.append(f\"\\n\\n{section}\")\n",
    "                for q, a in questions:\n",
    "                    prompt_parts.append(f\"{q}\\n{a}\")\n",
    "            \n",
    "            # Add test question\n",
    "            prompt_parts.append(f\"\\n\\n{test_data['test_question']}\\nA: \")\n",
    "            \n",
    "            prompt = \"\\n\\n\".join(prompt_parts)\n",
    "\n",
    "            # Convert prompt to tokens\n",
    "            input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "\n",
    "            if intervention_type == \"none\" or feature_ids is None:\n",
    "                output = model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    stop_at_eos=False if device == \"mps\" else True,\n",
    "                    prepend_bos=sae.cfg.prepend_bos,\n",
    "                )\n",
    "\n",
    "            elif intervention_type == \"steering\":\n",
    "                steering_vector = sae.W_dec[feature_ids[0]].to(model.cfg.device)\n",
    "                steering_hook = partial(\n",
    "                    steering,\n",
    "                    steering_vector=steering_vector,\n",
    "                    steering_strength=steering_strength,\n",
    "                    max_act=max_act,\n",
    "                )\n",
    "\n",
    "                with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "                    output = model.generate(\n",
    "                        input_ids,\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        temperature=temperature,\n",
    "                        top_p=top_p,\n",
    "                        stop_at_eos=False if device == \"mps\" else True,\n",
    "                        prepend_bos=sae.cfg.prepend_bos,\n",
    "                    )\n",
    "\n",
    "            elif intervention_type == \"ablation\":\n",
    "                ablation_hook = partial(ablate_feature_hook, feature_ids=feature_ids)\n",
    "                model.add_sae(sae)\n",
    "                hook_point = sae.cfg.hook_name + \".hook_sae_acts_post\"\n",
    "\n",
    "                with model.hooks(fwd_hooks=[(hook_point, ablation_hook)]):\n",
    "                    output = model.generate(\n",
    "                        input_ids,\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        top_p=top_p,\n",
    "                        temperature=temperature,\n",
    "                        stop_at_eos=False if device == \"mps\" else True,\n",
    "                        prepend_bos=sae.cfg.prepend_bos,\n",
    "                    )\n",
    "\n",
    "                model.reset_hooks()\n",
    "                model.reset_saes()\n",
    "\n",
    "            generated = model.tokenizer.decode(output[0])  # type: ignore\n",
    "            generated_answer = generated.split(\"A: \")[-1].strip()\n",
    "            expected_answer = test_data[\"test_answer\"].replace(\"A: \", \"\").strip()\n",
    "            test_question = test_data[\"test_question\"].split(\"\\n\")[0].strip()\n",
    "\n",
    "            test_result = {\n",
    "                \"prompt\": prompt,\n",
    "                \"expected\": expected_answer,\n",
    "                \"generated\": generated_answer,\n",
    "                \"correct_strict\": expected_answer in generated_answer,\n",
    "                \"correct_lenient\": check_answer_lenient(\n",
    "                    generated_answer, expected_answer, test_question\n",
    "                ),\n",
    "                \"section_counts\": section_counts,\n",
    "            }\n",
    "\n",
    "            if test_type == \"numeric\":\n",
    "                results[\"numeric_tests\"].append(test_result)\n",
    "                if test_result[\"correct_strict\"]:\n",
    "                    results[\"numeric_correct_strict\"] += 1\n",
    "                if test_result[\"correct_lenient\"]:\n",
    "                    results[\"numeric_correct_lenient\"] += 1\n",
    "            else:\n",
    "                results[\"special_tests\"].append(test_result)\n",
    "                if test_result[\"correct_strict\"]:\n",
    "                    results[\"special_correct_strict\"] += 1\n",
    "                if test_result[\"correct_lenient\"]:\n",
    "                    results[\"special_correct_lenient\"] += 1\n",
    "\n",
    "    # Calculate accuracies\n",
    "    results[\"numeric_accuracy_strict\"] = results[\"numeric_correct_strict\"] / n_numeric\n",
    "    results[\"numeric_accuracy_lenient\"] = results[\"numeric_correct_lenient\"] / n_numeric\n",
    "    results[\"special_accuracy_strict\"] = results[\"special_correct_strict\"] / n_special\n",
    "    results[\"special_accuracy_lenient\"] = results[\"special_correct_lenient\"] / n_special\n",
    "    results[\"total_accuracy_strict\"] = (\n",
    "        results[\"numeric_correct_strict\"] + results[\"special_correct_strict\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "    results[\"total_accuracy_lenient\"] = (\n",
    "        results[\"numeric_correct_lenient\"] + results[\"special_correct_lenient\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "\n",
    "    # Add section configuration to results\n",
    "    results[\"section_counts\"] = section_counts\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cae8239e5b443bb8e5c8a8b577811e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cbc34532fa4dacaae321e056859be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcb2a9de0f948e996d13dd2fbaa32c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d439e08994d4e02bee24afb7c741a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebd760b5f8a44c58c429da799a6d927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_results = evaluate_model_with_intervention(\n",
    "    model, sae, intervention_type=\"none\", n_numeric=1, n_special=1, section_counts= {\"basic\": 20, \"numeric\": 0, \"special\": 20, \"zero\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have 10 tokens, and 5 of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have 10 tokens, and 5 of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\nQ: I have ten tokens, and one of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'nine of them are white',\n",
       "  'generated': '9 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 0, 'special': 20, 'zero': 0}}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results[\"numeric_tests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c355b0b7673b4ab391b7e06b5bea2367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d70da3e457483386fa0ba02fdc8a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e889b429885147bc8df9a3c29d5ba35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "steering() got an unexpected keyword argument 'hook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m steering_results_hub \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_with_intervention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12257\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Can ablate multiple features\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervention_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteering\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteering_strength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_special\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 160\u001b[0m, in \u001b[0;36mevaluate_model_with_intervention\u001b[0;34m(model, sae, feature_ids, intervention_type, steering_strength, max_act, n_numeric, n_special, max_new_tokens, temperature, top_p, section_counts)\u001b[0m\n\u001b[1;32m    152\u001b[0m     steering_hook \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    153\u001b[0m         steering,\n\u001b[1;32m    154\u001b[0m         steering_vector\u001b[38;5;241m=\u001b[39msteering_vector,\n\u001b[1;32m    155\u001b[0m         steering_strength\u001b[38;5;241m=\u001b[39msteering_strength,\n\u001b[1;32m    156\u001b[0m         max_act\u001b[38;5;241m=\u001b[39mmax_act,\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks\u001b[38;5;241m=\u001b[39m[(sae\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mhook_name, steering_hook)]):\n\u001b[0;32m--> 160\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop_at_eos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m intervention_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mablation\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    170\u001b[0m     ablation_hook \u001b[38;5;241m=\u001b[39m partial(ablate_feature_hook, feature_ids\u001b[38;5;241m=\u001b[39mfeature_ids)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py:2155\u001b[0m, in \u001b[0;36mHookedTransformer.generate\u001b[0;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, use_past_kv_cache, prepend_bos, padding_side, return_type, verbose)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m   2148\u001b[0m             tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m   2149\u001b[0m             return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2152\u001b[0m             past_kv_cache\u001b[38;5;241m=\u001b[39mpast_kv_cache,\n\u001b[1;32m   2153\u001b[0m         )\n\u001b[1;32m   2154\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2155\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogits\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprepend_bos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_bos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2161\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;66;03m# We input the entire sequence, as a [batch, pos] tensor, since we aren't using\u001b[39;00m\n\u001b[1;32m   2164\u001b[0m     \u001b[38;5;66;03m# the cache.\u001b[39;00m\n\u001b[1;32m   2165\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m   2166\u001b[0m         tokens,\n\u001b[1;32m   2167\u001b[0m         return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2168\u001b[0m         prepend_bos\u001b[38;5;241m=\u001b[39mprepend_bos,\n\u001b[1;32m   2169\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[1;32m   2170\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/HookedTransformer.py:573\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    570\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    571\u001b[0m         )\n\u001b[0;32m--> 573\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/components/transformer_block.py:183\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    181\u001b[0m     normalized_resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(mlp_in)\n\u001b[1;32m    182\u001b[0m     mlp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_mlp(normalized_resid_mid)\n\u001b[0;32m--> 183\u001b[0m     resid_post \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook_resid_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresid_mid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmlp_out\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     normalized_resid_pre_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln2(\n\u001b[1;32m    188\u001b[0m         resid_pre \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_mlp_in(resid_pre\u001b[38;5;241m.\u001b[39mclone())\n\u001b[1;32m    189\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformer_lens/hook_points.py:109\u001b[0m, in \u001b[0;36mHookPoint.add_hook.<locals>.full_hook\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mdir\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbwd\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m ):  \u001b[38;5;66;03m# For a backwards hook, module_output is a tuple of (grad,) - I don't know why.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     module_output \u001b[38;5;241m=\u001b[39m module_output[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: steering() got an unexpected keyword argument 'hook'"
     ]
    }
   ],
   "source": [
    "steering_results_hub = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257],  # Can ablate multiple features\n",
    "    intervention_type=\"steering\",\n",
    "    steering_strength=1.0,\n",
    "    n_numeric=1,\n",
    "    n_special=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_steering_results_hub = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric_test=1,\n",
    "    n_special_test=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: zero of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have eight tokens, and one of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and two of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: zero of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: zero of them are white\\n\\n\\n\\n# Zero cases\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: zero of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: zero of them are black\\n\\n\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'zero of them are white',\n",
       "  'generated': '0 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 2, 'numeric': 3, 'special': 2, 'zero': 2}}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablated_results_hub['special_tests']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521abfe896f84e62b528a93fcbd2b6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8137788aa4f7475180cc5aa359398404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c614233d92c45d1b9e8d2b557d5a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b8bea0ac5f478f8c130346686232d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e982ac1b274d1f88c38c6e1e910099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8032a5a42c34d5f9d3879ddf7e8c8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ccf03d9a864f049bafc02ebbe17e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc7f703e132489f8a1977942de4d26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3037eb4730724568a0fae91d9698c08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8da1883b5a4b3ca4abab6d140b4865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1522a34e26f4934a18e884e5fc5632c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527ec79b5c164f4c800a279a76da59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6630058d42ff4755a151a511b9850991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3033aaf693754f9d8e27ca34d70c4ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e3fb08b540418792499d67f538a6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc598e01d43248688676477a84404ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b7b0662f5c4b9bbd450de4a1cdb3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f59e67ff9c455d8de95bdf95776ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894c742127084cc690b270f6572be5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a9bebaa90b469583059683344b7244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5176d6774e04ac7984cde4ac987fe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c4c2556a344d02b0318cbab23b3e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafa2c3352e34bbab17f6d2c7ff22134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f513efa55abc4bd0895c3b15f58e7d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7512bf5e11374f918b8123577e16ea50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b036f7fefd43c48e90144a8f866abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a3c2014bdb47bd8e7a4ec58c7a76ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcd2bf362534f95a343e0b946399036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000c0516e92c49ab9efe4e425424989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2068e0056b6847b48bc1ccfed50a2bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e6cdee40f4e26add7311f2b09278e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f7c5f944d42f58603427f67aeb9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af3780555344555918756e28929c4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0347a7af7695446594008e3c8c848323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1dc8c7b91e441291740189113b8798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76762b56581448d9af59601b52249a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f27c8472de48d18f49f4d044357e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4541647a68546b798980c581300bcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6bb510ff984b6bbf7e40169528cf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc3a0420fad4dbab6a5b99705229814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f468c00b5c34bd18b9769875b3de499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea675ab9c964ccc8bc1d598fa974c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71628c8212d74fb5b0b3a6af7a28ea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bd1c8a319a457b8d9db25801bdfb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab2c132eb994c6582a96e62136803eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf3c9a1b5cb4edfaa40c7f7318ac580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6abf7cfb30548e0a9486ca1caca33e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8db0e833e64cd4aca1981d5249cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de95d3e4bbeb47a08de69209a1f0a974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8374c288badf4503a8631dbea8d26cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759070fa8f61439785403ff72c69a5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5304efb4948b41869b91f5674d5e246d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4611bd14ee4daa9c907a3b4d6d6eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba835b9f7d4a13940bb92f35bf4e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec732a1d05544d7899974af815db85f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809d88c3a19f4025af5323b183020dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10681fc6f906485b89cce05d491c0e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8609b7ae8a4fb78d208d600c633f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686d6426e30a4958b863bda91066e418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8df839bf2ac44ff851d99f376b33b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dbeb9ee43d428ba3862c20570da2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e10b7c040e41288430d8ea7e012c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185d66c4ea1847fc889604551699e0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab35b8fb955943c18e12710db72f6b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3435f9de3d34476b6bc894453971001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1a84d4ff7c4259bbb2471123085876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffb772787414291aad59a11773f0fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100d83d2410c4f6a860ec9b354d3dd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb5d2adf7824002a742a8f8ca7e630e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d22a67da3499dbcae1fd9f13400bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9e40fef06f49c5b0b3ad2b3748a25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f369f2231e5248de9e015d3dfa8aed5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df056e18e07d4803a55d78ee022732cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eba94b553442ca906b2892aaf4e279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e05a16eea6468682f3ffbe1cb5ed18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f42df0dfef543ca85eaa012873c9282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c0b3e7ead74eca9882ddf0d63c8e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2a6b957a9744279c97f36aa3b69b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc414f4313c54b2db977e527797f36c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1d39f9ee84921ac6c98aff28676bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ac83ff820a49448f9d2d9ba50192de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6155c5b32eec4ff2900af8b8c6a000f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b43279d0a748c4a6d908ce21adf6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c60a7ff45f7439885cdf7cb6ec07fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c89c7cb75dd496d822f99a0c61c3b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfac4aced7034fb6a15c69ebac48fcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4031663c34416995e8a9d5d91f8671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b5c3e9875d42ad82752fb56a0768ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db534fd27d4595b91f2189b312f0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7cb925408c4736bf223bdd05911118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b15d418e1c34e6eb54d0e1822e7dd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888607c2d091435da29622bed8e968a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebea44c89da4efe8b72bdae2bc05d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe44bf531a4292961ac097ebe92b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4be561955984a8d94d4f9f5dc97016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd80508726142f7b12aa2de0751cb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bee063257a48edb007a4fb7765b5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc67e4ba9fa44b2bf9c07f9d954d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bd26ffc5834f3d86f668dafa371507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479222a81d2a4c76b47a605b443e5b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f435a9a7ad2946fea943a163dab309be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d892d395cca41dda69a69cfc4cbec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c3282690084c86a30eacf4bcc15aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test without intervention\n",
    "normal_results = evaluate_model_with_intervention(model, sae, intervention_type=\"none\", section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 20, \"zero\": 0}, n_numeric=50, n_special=50)\n",
    "\n",
    "# # Test with steering\n",
    "# steered_results = evaluate_model_with_intervention(\n",
    "#     model,\n",
    "#     sae,\n",
    "#     feature_ids=12257,\n",
    "#     intervention_type=\"steering\",\n",
    "#     steering_strength=1.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(normal_results[\"numeric_accuracy_strict\"])\n",
    "print(normal_results[\"numeric_accuracy_lenient\"])\n",
    "print(normal_results[\"special_accuracy_strict\"])\n",
    "print(normal_results[\"special_accuracy_lenient\"])\n",
    "# Test with ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\nQ: I have seven tokens, and three of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'four of them are white',\n",
       "  'generated': '4 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and nine of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'one of them are black',\n",
       "  'generated': '1 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'two of them are black',\n",
       "  'generated': '2 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have eight tokens, and five of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'five of them are black',\n",
       "  'generated': '5 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have five tokens, and two of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'three of them are white',\n",
       "  'generated': '3 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and seven of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'two of them are black',\n",
       "  'generated': '2 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\nQ: I have nine tokens, and three of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'six of them are black',\n",
       "  'generated': '6 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'one of them are white',\n",
       "  'generated': '1 of them is white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'five of them are black',\n",
       "  'generated': '5 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and two of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have four tokens, and three of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'one of them are white',\n",
       "  'generated': '1 of them is white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results['numeric_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have ten tokens, and three of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and one of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and seven of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and six of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have four tokens, and three of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have six tokens, and four of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and eight of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '1 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and seven of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have ten tokens, and one of them are black. How many of my tokens are white?\\nA: nine of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and two of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and eight of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and one of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have five tokens, and two of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'none of them are white',\n",
       "  'generated': '0 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have nine tokens, and two of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have eight tokens, and one of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have ten tokens, and seven of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and four of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have eight tokens, and six of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and three of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have eight tokens, and one of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'all of them are white',\n",
       "  'generated': '4 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have three tokens, and two of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have ten tokens, and eight of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'some of them are white',\n",
       "  'generated': '1 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and five of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and six of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and one of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have three tokens, and two of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have ten tokens, and nine of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '0 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and two of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have ten tokens, and two of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have seven tokens, and three of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and one of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and six of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and one of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have nine tokens, and eight of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '0 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and six of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have eight tokens, and three of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and six of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and three of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'some of them are white',\n",
       "  'generated': '5 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have ten tokens, and one of them are white. How many of my tokens are black?\\nA: nine of them are black\\n\\nQ: I have eight tokens, and one of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'all of them are white',\n",
       "  'generated': '3 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and four of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and six of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have ten tokens, and nine of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'all of them are black',\n",
       "  'generated': '6 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and one of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have ten tokens, and four of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and two of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'none of them are white',\n",
       "  'generated': '0 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results['special_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b084bed6964c6aacb2291ee8ce336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc96dfa22854586a2a3115190e591fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76ea14fe4c64568a9c25a4935f077cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725aea008c54c009011a2147e261f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a778044599f494f95153955ae0d3725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b89f0b73e694f539b9cced00fbf33c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb55204939f94e5c8586e7eb901c90fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe4bdb5e848427bbad79535b75dbcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a37a246b73e4986b7d52cf215dc4c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff3d3993dd45b7a646efe02e96c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8b399b75d34ac0b94d88c209ac3e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e648e868fc9547e4a44b505217cfa116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6791fce8ff14f93805683df493a808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922cc02fe6eb4fc2b2f9099c0400a163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfc9685eaa348f2b3292b7e6a977299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf0e651fed948e6bd1b8e280068a6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafac62a0dfe493e8d93e243454ead7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c149b7a04ef45d6abe757857b8af9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244aab1031c448b0aa33f9d127f068c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935ab40662204203973170104f31141d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2eebf4f9634838a9f972e44a459b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e760b6ea640dd8080d820a859a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c83aa30756940d7b3544eeaa1939d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cb208e035d4db9880aff7243a33805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce5daa2852f4f039d7b8a4948fc7476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c70617fbf134fa4a78ea5f134285f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588c783ae67b465687e181efdc36d79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3b6c3af0f84c988afa45a0b56d110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a74afec6e3e46d283a3d61382a8bc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee0dc9f46bb49f281f9dc3f7700c63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a3efd4e4704eee94cdc12958a18360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6861338b13c4cc99e7eb7d749211016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a051df1c83d94880826eb7af547868c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217c4c1e681d40dfa20688ecaf6ed827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab25da7821e44ce993d9af0d8bdcd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c597e78fd7041989949024aa7a65b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a72ed035e1340e99f73d5ac440de202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569675a9ad0b4f3baebd9e3a65073950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec96aa03ec5443ca841033978a69cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830dd4ad6ccd46839ccf9b7bc4cc4a84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbc4c0925ef49a5854c51da3fb0a7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b932f883e7244457b114b531b69707d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac698277e8f4214a6b1df499b4824a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a7b3807771464bb833246adfa557d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73733cdc61a0423b8851da55c6377dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c24cc192e614e80990c0ff98c308859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8619ca52aae4ded83543a7f061bff72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ee45c740d84642a0db34082ea11d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0beca49188a4b57948ee54f11eb2641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cebd610bcea40ee8904d670b26f50e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a84780df854373adb1e5c37a033e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e51a304460b4603897c9affb16d6996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b539d154ac40a3b6aae8be14cbc4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200ecb5774424dc1b2bb7ab5804cb379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8e23edcd9c43d397750ec0aef20155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aae983899b94e9b8b1679c730aa494f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213ebe8b035548f288ee0a4d0913f005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aac1839948e4789a6eab078b9c12680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff983ffef644f4a91ccc68bf50918f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6df54b5d1794d7b9f84206e978fa061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972cc0ed95aa4b9fa9e68f741869cb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5d560766964e5caa78ae3b0ecee89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b9026432394354b67b1e41144b3b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ee570edc47450db070f84be6672f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e63e4fcd3f24af38fd929fa44353e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aec87cdb5284e39ac81919db3604c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c628a2c2a81417794e8b89cf01cace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee7eef8ea58748ab8426895f1c565a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac2bd907c6d494d818a5d2602f7bff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9b9689a2de4feabb18619b1204b364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a2e98435224dbc82b1a4fd5cff5e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2356c2f9955a4caab30b5ad5cc77970c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9b006c0eea4dfa8cabc2fe6ae00f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3a137d00cc4f5198956a88a1784b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f04c742b9934e0fbe90ad9c8415e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4ab62f0f3d4d8894d162e308d0e7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4c308dbe514bcdb8ead68d284a0f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3123d6610b422fbdc14950a410f048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c617608ff3e4c618ae452b9b0317951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c445ecfd419249deb29110347eedee7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5013eddec7d641e6a39df10d1e165991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1032210561904590b36c79458c18bac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09013b2e44024f0cbc3290507fff69db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b2e1fa47554fb085475804520f58cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4f421402a048feab062c484f37cba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfed89dfa9514ece9e9cccef850bec52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19622c42c0845bb941be2c9ebd7a653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f50567820d4254b8068438d343130c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51ca07eb86d4e8aa5efc792394d433f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b49c6adbde43688213282913c99b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce67cbc503da4cb08775eedf06dcbd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983fe1fa0aef45ad88e58c2556b0cb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3b7469dca646ea8568d42795d121c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68d865367b64e4896eac22275bd2175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46a2bcb08dd4d7286a48b39c0da32fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbb75f404854ca2a3d876fbca946a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3122dc30df9a47dcabb149a15ec9e0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bbe9179a546448594b80c20a349959a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09dd261f3e234edbab7d1200743a9b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918dc4f7aba946518c0b7cb387013d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e920968a594aaeb4e36f31a63afe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c921646f734f33afc22f99e676f3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d06196d11eb4127b150648c527577f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eea9b3187574c1d96e343ae8de6f483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b88862dd5441484cbe8d4851cf65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12544660c65f452ea0f93c13a163f666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc94c85179a485589bf3fabf419099d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7d80f2da1241bb8055232b251b0990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52947800725640108f2438f26a0de177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ba60e784b463f8943c74b542b07c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9f47a03d8c45c99b525f6b878d790d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f80e8a327a64e3c9f628faae663dd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5abf7f656c5a40d09834491e8680fc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a6669e4cd8410baaa595d43830bccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ba8ad77eb34574ac4595e8f25dba88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357665df2a084b6b813188c8106334dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc172bc597842fc88ff52de55ead943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4984295ebaa4a38bda3b6673d4979be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11cefa85db243d0b73c056b1e65d754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08d907ae29346a988e0507d594ba42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d40bb4537e47eeb8b0f9023f96c41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6ae4242a68473eb07be6b11830292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b178b65dea1943bbb84ce05679066a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca1a856071d490e81560fdcc856c689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514593713f5a44f1a8be2bef99f31608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfe23a17b424cada7d341d253638b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1325946ff20c421bbdb075a3a243bf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a269daf109394f798dff5153daebc0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a64194562746ca84bad3bd0ff118ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0b2479e9ac44f2a8ce726f960c8185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee76c910c7a84667a746f1db89d2685b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19562fd49364f5fb8227de1d590800d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4155539251694442ac67da93c0dd0ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e867903360c644d7aa9bc89b005a7ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7968e608edca426b9facecfc1c9ee3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ad3c523ac84f72affe101c217d080f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58da7eb7d5334f69ba46bad2a00f7896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1c6d058ec44205a99517b4db07cc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf08a44fa5a4412a9aff245ac25c0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8553a5adff55494180aca2dc624a82c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a2a65bd7fe433e8e24ac5e3ace0dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51af1f28effb46f592a2221fe2cb4183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9798deb1179145a3880fa1e8ed7bd603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec70ae3258143b39ec32f51206c183a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb9b1b5b33c4a29bf03241a2fbd310f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ce1c51695c4aff9d17e30a0e7f1836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d563eadcce443c38c51ea9d95515d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bad761c4154835a9765881a3be2087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf759cd7d7f449a83c5130035423745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9abe020b70d4398ba856f7ffe0b3fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497367b7619f402a9e67b7261bff0cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84888b17802a4d2a92d2ea5c1f382b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dda96ac8ad340ff9bd0c4a0c8ac0077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a7a48e79c54c0d8ac8acaeefdef9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90e2442ee0d402b89401b597d6dca8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a602ac66a0b544d094b6fc7e9279a9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3baa6c889a40579e2f3e823f35d583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9dc1aad43b45d39aa5902256b1cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7530d35f2944a8bdd903f6c016148a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13f262d60ac45fdbc36bc6c01d80d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4310fa139ad046049977c0dbdae10e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0619fabd39e24bff936d655f984350c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471ce60300dd468bb544a7b6d9c821f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0dee8b11bb4f2f8da2bca979078bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5894eeaa283942acb7616d3df705816e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ac0caccbd44bbaa1d69c0733fb2ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7844c0fa446743ebad11ec1b142f2207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f5d94209ed42c88fa94837af6a4619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e17e3727434331a268a64c505dfa6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f947665379134b2793238020b915b923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d58bb866a53481e8d5fc63361e8331c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b329137684dd435c9c604fa9ab4cab71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d43f54e9a84aaeb219a411e16f0816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85fa872c6e64f32947878f1375babb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1554cbab7d234b399f6a7ff242389225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46449f40dd844cd7a6b0e0e92662eaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7458ccc2606d4dc2ae17cb32faf7ae6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72fcf969ea14c91a416378fc4516c37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9abcd2e79cb404f9c7f89d7f842cd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0aa3ee037d4db6a639b6c9984b514e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1d0d82fede4558be954de67b33b298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a652290d4f6548c78b7c9b78f8dc488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e785b528b6e47d3b90e1c8b9103447b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7146863138a943a4bd7988bc8cb4d2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce138a903d94db8934a19f4c133047d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b0066d2a2e48d9a8c87f9456c6c45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76b84f98ea544e69babfb3f805da51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa56fec7c05147c8a370c1901f70566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b4148bc5004fa7a91132d405f55095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a7f60ef2d24de6a729aa1beb2eebb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35110425402245b4886c3f34222ba100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1852f76318b44fe39cf460a70e2bcfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e254357e10428884a36604d5d348f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67b95e897104ddab4552f261b1d047c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927e9b69f25546a0a3b361e5e7046bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26094dfc4d0b4bf889eb615680aec1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f02af315ac4820b8103b0e4ca3d4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25722a2edec742bdbca5eb342c3b6db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771042865db047e1a1374c2bbdb93b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66551e722c004df09bb1d96322adf370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bbe48ee9a3447886f7136d6850ceda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e4dd0707b94c3abe4c815c5b1cc867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d583ab6819460a9b4a504189257dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f502f79406f24e1cb5e1c580138678b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4a6e17fdd94b1ea0ad67fa4f2d9b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637e302c843d4829ad8205eb8b48f413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c29f6107f8421f98802a9e870d5a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14af44b396b8473fa2326e05d97ad4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc11eff3307c4cf3b15d2462c9d9029a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5412ebb435495d9b99a4213bf7f344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7492fb25e3904b559151a4a02d3b9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6daa408a11d14e1e9993510225438687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bec42939a8845f8b8cf63e51860e42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90835f76dc240a483b8693570daf5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228f1185ea944ff0a70c0d35d43ea132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774422e10a8d4522855a64b7fc668866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc14d494ec9048efae696f640db4ec32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e07a144be443d48572099c48985d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1d0283acac49bfbe6f5e2704608c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c7545b3941470d88f6a1d7b555c3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0427cd8015fb45778b76dded43343228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a0de999411403fa2a87534efd1b573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0650402a98c49c6b7f417cf008c7329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b187610eab924455959a69ab378f3d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c231fb147a2d4b01a81276e2216c455f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710c2f3700c8443ab4d4ef80a54c7458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4947e99918914f51b778f5e480642253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fbfd4bef43d440d98626a81faad9296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f18ed60b584bc3b85e8e2690bd06e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e749b59ce694e9c95157c3e2ca93a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888aa38331614d6cb83813778bc04621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3776fed9907c42cfa1e28b339fc589c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039b357b0d13475a8c1c12d486348aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6acac767ce444c28ec9aacb101418bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a68983c18a4bf496ebb38e14399504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacc4fcada8e40d39d6ed92734c011b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d6f4a3ac854729ae5cfd73daf5a870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db1008054894a2fb62af7eab22d7509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727dd85b9cb749a7b2647ac3d867f843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d051a4a7dc4b48608ba0343fcd585c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ca6ea0df0243459c6260ef02927f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c58083279964ac7bc0c377d705a5113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c12165fff7430681a6f4ea4486f136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451c775bff8841e29b30ac8f0114dd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7862616446341aabfa327000476ac4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271279526f04660bc601bf15cee014b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764987d8985f4e269458f2706714bbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e2e8e32ca54367b98ecae5681fd994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256108ea86694dba8b9222fcb398339d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0d4b7963944c77b6d2f3344dc80e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6662363b545149bd8c0dd4670196ec59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac297a136c641baa273438a0f6ed3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e715c6f175a4245b663391c2af1c856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2bc013adb0d439c8458e9dfe50c06cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6cbd42b7224620877d2aeb73350e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d30e9703124568b8eb978b8a01f700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8eb8584c73149ad87c2a38288158188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf3949249b344da92addec94001f300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f972372611384554b115ae9661c5a00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f028fe3e2b84cae8af4d511a2ed51c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1ad62c1672479a93ae05fc8ec1d7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b69d392fb248738fe8655ee0e12ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4023278c14d246eea78ae313ebb7b881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffec2ac11230491396b7a3f42321db57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cdc0a350e04966857359e5fa9be217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27dc920b4fba4966b1fc5fcade765fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9b6050b5da47b0982cb954f1ba71cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4e88232b1141e5b99688d66f2df763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6449eca4b23a4593b32e54005e67b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fa63b7c62e498f959b5af758d9c8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d6ab4bc2f04091a2edd26c4f841ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf695540fc2427fae2574020b6eed27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de008bcfa5fc46bd82eb83f8388fca9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdca8fb9ee447b5ba623f0b3ab23ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936773d6e2ed4c4394bffb0d2a103031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef900e605ed428b9a06413a6fcbf3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43d17edc3c0402ca3b996fbc58f9c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7538484fee54180a7a360bf8dcc937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc5ea7b430244a3b316d50edbdcc66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a9541730324187af6789a5fc32ada4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dd67c070d04b6693cbff1a1a7e5a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98bc547758646cab39ac56be06252ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9a4685355644ffa468543fc68551a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ea04fd45794551b4dc5247a049e4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85021e26f0a4bf8888d34cdf7b19249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a02015ae134e34ab1b618cb77b7fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf0b2b88bbbb4f65a601e093b9e4858f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ce620876b24703b830ed1a8db45f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d117686b3a64d0eb96df847bc8ff680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7073fe4548264fee98763797de144539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae3d2d527904674bf374e8b44cbf1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d557e1c74a547478c53ed66f31a8bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bb8b7f97604914b77de47a1a39a2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7a343ed1574c8d97f20787d8363dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a0a0a395eb41a6997f139946c00911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c260268624481faf2e261d59cb1cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c483baae9594dd585f66235a23a9be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc20000118e44eb8af4b84e522e03550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06488405c9c54331ad99d57846435e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c3b552ef6c44869e900dfede4413ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a06e05fd1a4c68907d0fea1c844b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d5d0d3377d42f2ad55e1bbbc477262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58fb10fb30c4b2298fd7a95fce62cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e7db92b75401dadcbf457320d588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e719c387fe247aaa72d71f81da9cde1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9172b8e90604f969e60dd407a36e896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b6b8c48174c90b70e4f49dfaaf22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4d6f29d5d943b899b5fac3d29317a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed69272a72644b4b4fbe9e042beb075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60da42b178c44b93aef6ca01400f7513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87eb367d80c450297f9c923e38f6bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb66d282f7f94e4ab019d9e7abd5493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c634648284914950882c8d0f7803ab99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f44b7ba4b44e288e6cacd39ab43c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c1ab80390e4788a68db1cbdca543aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c18284af6554d7f8b0dcc78bbfe0f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e449e745eae2484797ba23c62cf9078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0c95ed5b024796adc03a1874c9a47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050a05dec47432e80c8fce0754ce8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aea604688949279c8259e07cd0c71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9ae1fc57764c3faafcc160e7c8f105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2179a7f97a34e418b36ea4db1523c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ee867e33aa4bf48fcd6f879d652c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f93c0df4324c06973f0e0122dfc13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8e7da829094b6aad209bc07b7596a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc9360f3b4c44e09e2ca35d686f05f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bd9d0256834b78930d570737833dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4e7a0bb5d84bff81a35ef103160200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666d0823ffd44f7598c683286c6e3e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dfdb2433738447783913e0930fd763e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cb8d78eb334cf895f5c079f753b613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c24274b714542d7b2ef6b4eb9520f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e642a7c8eff74dc09cb383087ceff430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df63dcc2d044d12bb53482bbb9c19d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de8f9965e0b47c19e12b37adf950779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc84d6b0ee841028cdee58d8527d4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e9a4f1e44e48a7b8f4111164db9c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb0c25d32db428ba15cf16134d64c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ada12753254279bf38556f319a15a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26e25a73a714e4db84be08de7e49fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769c9463bd834c05b60597818c2f21ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7c5f8591e04e50bb37e97fe7787de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d9c3c1a2f147a686000928aa358afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aaf803921734bbb93abe39e03173cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d0003e6e5f4850940b524152c6aca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b09f56ec0da401794b429328481f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155b897ec5a641138f5b338399c0dd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83560890019443ce9c161e76bef6c63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17c58a7d3094c269752ac69070cf086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaa5d079f644c2bab673c85b9b7ecae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e331db3fa844f94a888f4ab081859e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d33c5ab3fd43e4808e489866279eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e5416d545b40c8802ef3f529d035a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbfcdbc8e464d6da12668f97e5b0bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52f777a5fb6484ea9e62a17e77d9a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298ba6bc097d42ac9301ba2309d72ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b29db5fe684410a786691c3368ff82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a437d1aef6b420abf866c5c2189385e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de637f455590424da487df7a1a527957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8b2c32943d452688374b9e97af882a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2a6e7e77cb46c68c53662728b23da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e64c3c69f4544619a22d23ba60110cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dec6ded229a4b449b7ad5cc82bd9bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6780dc44ec4048841f56547bce3ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53346ece0b740b284ab56c17f191577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e5acd37dbe241ccaf4d11386dfc5b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4afe6a31e045868b8d63f284190ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f765deee1049369cef8d29331e4e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c31ab5761dd4341aa79a0ff34504158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5deb4f366d745499ff6d85f0fd8543c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344724a393b04caeae62f83bdc7a86b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d0cc3d99b04ca188b4d5d89d8b2664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b207a0f86b946039c259ef2f26f8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a640ffeabbbe4701987bad07b1dd6c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cfa831a77a4c4aa305ba107fee0684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7711b30827ba4238af20d8d3b53a9024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f48236728c4408b0c096c8f3ab60e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a5ba1957364e0db338b886df3acccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb49f8b06abb4a4ab2063e92281a57d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7a9fda0bd041e5b7309840d5f919e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3d7c74d7c5432ca1c52e85d635ad81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6338d81102db4a138a8769b6d3b1dd93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054d158c6e24ee3bc94ef4c0cb8c8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c666320324e745acb88554f75fb4a47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ca73d214dc4568b903ba1808eb589c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1f189ff1094c4dbfcd0d2a9b34b3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c53b35e572419184f24f8280bc826e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a3452cbb5d44f7a1d4f094c5f27c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373756ad4c5a4fdc80df100221781892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51e50a9d8e3484a8a3b5d1b05482a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41ee81852b9400da007b8fec15e5590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63427e00c064743ae5154608a91bfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d086200373a0408484712f5b86a32f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df5ca07463640fa9e9a5bb4dea5505e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507a4b522aa4de49878b182070b91d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6643ff11f7204b058548af3b668c4df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664c180f3e474107b85f69f228e297c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820da7a4649a4e57a0273b6220b51eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea2a4e510cbb4e63ac09d025fb0299fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfc5be50ed84bb8a6891b00a3816473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1098c046984761a060d47dee12c75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b8e5ff3e7548689c0a854d7f992dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eb421049254427b732851aec58c5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b9b3bd53c74ba1b0ce929b259e5446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9a054c665647ee8848a838d75e555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d728e6daa5ba401ba79284bd7ee4adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30600a5a12864f8ba6cd64c22f31b3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84aa970fec4434a9e47845ff2cab585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554d3a3ea7a14322a2ea2dede0c9716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e1fc7dd7a64a6eaa490600f220181c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efeb297dfb764f8495fa587439599348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd0da46749648eb8b458d1c13bd9aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9a02ce76e6434d9d690bc3db93f7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89381d0dd7946feb46ce6b2132edf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bc356038304e1c96709ab455855338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28985d947a94158aa675bb96ccb4846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ea12b76ed84909a6a23ceddf34f10e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c6b5f66f57493fb25c56aac68dd46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68fe403298e4b639402eeba9a8971e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44e0b19aa1947f19b04074e7932d9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab754b37a7246bab375c89d09446d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fdd9a5512e40f49df41c13147bb3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e84e3facb4418a80bbe4b38c72eec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b31294a3ceb4324b9703e6ca5a6d621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7fdc0d19d649f9b980cef95e2510ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32764d126a646fa8e79ca8c37c918ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840b42ad10bf4548966b7b6efdf5a3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb86df01b12744d7b9cbb3678d95eaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58ea261c80941259f393f0b00e45689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a39205bd32435482a07b03bdf9c2d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df8e3aecb054a67aafabb73d1922ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa27b01abf54d61b35a919b26ab09d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192b8f9b506b4185901b9b8b0abe0c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9518080ab12448f9145f5c1e94364ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7f57132a354abf92f6a3570cd90ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4dc38d169440488ea7f59abdfbe522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6701be271cf4957b9828e3d80ef18b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34c4a5b8ff443ca821836a6588f239e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101f5cf652a440d1b805d3af26638d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7e2dfa92a74edbbf439b8e591669fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0f26b688904a4c9ffcaa32c8f9804f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce878f4d1994e0a97bc291063d85831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1203b6676aea46f18e1e31d4f9775285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6997c5f1874431c85ca08cd082067dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b25fe47efc4d9da9f142dc42c73a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6862e1fd7074b24870f4b424379e3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25625ea44a724675b7d0052bde2a28d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c18adb67d87474bbd06cd2bea9e0335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5fb7f378414f988f23046ec06c098a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd704c3449b462a9019ff34021a03eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ccea1053b14baa9bd3354680a0bd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f5b49cb62f4a6293096bcd091983db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09cc379d9dc5494ea546d665237df258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1388ad36a63a4b9082d1573c0930c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb84be7abd642609e0557d61d361422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3fd6e5100fa4d9b80138b04a1a6c9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97cbf59929d47bc89ea7c6073f4a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aacbe6983140f586f01871ce9bad3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f60c0ed634a41a3a64d7b92bc415b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c959ece8446e4e8dbe5f9863498230f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aff0532404d4c929d74f7efa7c2e006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c090e1eb32994dccb092d4e723651a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47cc165ff9d4594afaa9a3bfc76d431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a522379331497183bfdc2687e918b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cba73bdd6b642a89ef90f2e6f85836d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de7b71e01cc540b890952b84abe5b7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecf71c67fe4420fa0bd178836ec8a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a1560e5c4341a2a4b5e5d79434f3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00044c49c9af45c4a4f38130945ed760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d952e350f8c471cb68edd1f33ee8510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19e512522e14b85ba338d76c695a3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235e44b5d1194350b508814f1825fc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b0fd957611489a97540b53915db720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1297bb9fa089411798b0c80268c499c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4658da62334f4d8797379b8410ad5fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085d65e86bc14914861bc0e6dcaebf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586eba20fffa4ac0995600714482619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88214342f3447b18f7e081893a86934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b670078307844deaeda737e32d4bc07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bfcc185fa04b95a17b1bbd77b128f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a991d9b41557490cb34d4b842a91a959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4745832e73f3418281aec3330be3ad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc7b9274007429dafb43f38583011cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa91c5185b2b4f5d8090473a9987efee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04d60214a2a4156a951777d834c637c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53da9a0af9e443049de30ce349b94fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17d8ca059984c9f908b1655820cbe0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fb8fbb881749a6a273e6f5a04f3fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f728303dc69c4e159034f2d365f398b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14e979d52ea4d90ab9950085fbfad1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be26229bfd2144a6adae8c4d274ffb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cbe5305d104f92af244ea9a533736e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85362fa0480404ca4994f85eeadaddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430bbf2e7654485caee72887d698ee9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5e5fefb25f4a38a72f7b52b9a72670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba45f085ddf4f72b7111974b440a89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f35b191f82c4781ac05e4aa01c73626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5396867b38f4f1d80568628e6f2579d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b15818624b404abc64fc8b35c96297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7344277b0e244094bb1a92d3bd7a3082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19541dd1fe384984b4db17ba4a4b6357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71e304153a64627a3a44a94eb896618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0108e6193ffc4b6199895d7430666c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f63ae6c96524d0eb00ff26e73baf395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517d90c9fec943d297075e97f32c5301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87eeb612cd8459396d919dd19179315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272f31f9b33f43e88d28fadbd4e166df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5383fef5ea4d128cd326c9f1f447e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cb85e4470a41de809c7e395d980201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af0755028c14d42af93d8a1a4e734f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211005ca7bea48e28d2d5e0e3a5e3b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479827f0fce142aba346e403577aa139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359c19c61ad84748afd023eec398b0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1081702773d4aa8933b9a9b940baa11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16916c39745f40079559e020053e049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with ablation\n",
    "ablated_results_hub = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 0, \"special\": 20, \"zero\": 0}\n",
    ")\n",
    "\n",
    "ablated_results_some = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0}\n",
    ")\n",
    "\n",
    "ablated_results_all = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12649],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0}\n",
    ")\n",
    "\n",
    "ablation_results_spokes = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12649, 15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0}\n",
    ")\n",
    "\n",
    "ablation_results_hub_spoke_some = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257, 15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b81038d10d48bc8cee329982e1c709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c6b01d407746bbbf67a67a56db59b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51429295d554a5696d5854253fa76fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f61ccb57844eb18cbea7b73f13eed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb038454877f43b8b019ebb96f981421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0add36bc236340d9ac48465c8ee11885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c63db37031ef484ebb1ef1e948e9a4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258479fdb38e4c09bf646fcd7062e61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030cf7b1b67e4ba7b4c17f48f3ec05ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424623e920654d8380f693fee0660176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85dacbff49047adb61fa412c003c49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da95c51db7794ee6a74787a9b16a51ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d700f5d2522429a8070ce4d5727af0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6030c8ebc1b4e61aa54a07d88dfc90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8eb0f6f6f745e99b251871891880e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e970c6f3523a473ebaa14c3345903327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a032d31f4e4158ae1eb0bf35893aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d693c34e0448427c921eb839b2bda381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24d8a8147924836a3fce6db8e4616b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0961bd5a2659490999c6342e9b37c824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daffa3153f84715ac08a8cc6cf492a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7e5903f01b4c8ea425eb48f5de1ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13151e7e5a454aaab4e2a3543afbea67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7059f8efd44bceaf0b955b26ae1cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989117e292b34fe3899a3a72d0b0a8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d82e47f60442cfb3afbfb571344aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b46f7a803f14eceba37a6a33049ed28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8aef3362054fa3a58265f90f5e4c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91950ff1c6e84094be1d29aa0c797391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951fa641a8541f4810126e994d0abb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a97033623948d997b10b4acbb9c342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935e78a2e4644d30ac3c83c59a230365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8654037f47a14e6c866079045231470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655893f5ef4844e1854f167b126266e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2dbba255ab47bf8dc8b76ec4245fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dddcc1943e48978c0f2987534fd9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0a2b79b18345878410e13da93f16c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0651d0fdef496ca41246c95b1f0285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4420cef688c54a408448164e5ce28406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408c55d376f74a2b98b16448c2fa062a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfa67969adb40f2ba170b71db056e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e943f7582d4ba0974d860541e21dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c07d3f9a1d415d9a980333cfc09ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf84de15f5e4232b3de1b945fefa500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493a895775ea41c8b8990d3f7aca5096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678edf4e2f3b4eeeb901e9558f4a53c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a41cfaa14341408ec95f3130960aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35befc658f144bf99ba2ae835cc9ff5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541e59be3b2e41659e59de20ef2c59d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6070aed9e04b919bcecf27e16cea3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f0a7e31ab14aaea4b47a6364e20d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497e375c2a9d4aab937877abcec7a876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cd35033d1a48f181c9287930384081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907ef8deb78544e79153b707124ccb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5b42ec4e7a40e78320558a7b8b67a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20725baf564472aa05248a4f8681619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365a7a681404aa68ea9e6d6097c2e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c984c01ab94a44a445c7ab32d2a9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91d14d1ac864c1c823f912c0cd1602d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32876aad0ad347efbbb016d83bc94454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eead7577db74377acad7cc2361b7891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabfb5525cfb48939535e6162ef5254a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd92de1101404e37bf734970705f3165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e00e2492844c8abb247a919b86c59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898860e1f2ce4527bd500be6f892e6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b3e4b5e2d24705b3f8de26e4b01773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b995d8ef3f4f76ae11cc8688105e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4d696595de4d3899e68c5673e0ddea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c61b2dd65144bfb09fdd9f6ff39303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f187ad451a44b689baf019b4e01406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7713308c75344a49ac0d3358a759bcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b01df09b2d40b3a999d7290c459270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1278ca498f584560baba6ade0a4c3633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a16ba63d4d41b398012dd86d752880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca88560b79b4f70bdf87085998de9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc786727bfe4f8bb769791090c48d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9131f1ac7844c98830c739ede0a3edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa7f5593a094460acc08a91b2a7f0c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499056137d9a4e938a89deb31fe4f43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd83256ea3874e31bb46d4bb4defffc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d9e915435a4ba8ad67acfb50283f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa5883b85f14210b9b0a58b20034959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fb99fec40540688c35924c21d1f258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68932cf0c6214318ac1a6cffcb01be18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b45e8fc60fe4032bc2148fb2053e4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d645c948634e25a87ec1e949c8730d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48beb9519b044189721f0339f6ceb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712f60ea08c14b0fad41cfb4830ba662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b244e2c9af8d41b0b12d089d639940f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46c77df0c4148b68db425d1ecfcfeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74475af7994842bbad885a286af0c94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90dc5a09b8f465ab18a27cbd06baf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a171f9535b3742c2ade8e07c5123f3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bda3683538d44cd9683c30cab20a184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec36686565948249ebc8cca05c1bc45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2eca1f24d5453389a6273610d8edc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8264335bb195450b9e2657fbcf39d539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a1cd46f330403c8112cf6996a12d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21ac7cf3e07416f99c16b178934f3be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1087a88281f6435c952f4245c0f62845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04960df022eb45358e368fc4e555b1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f283b1a04ee84acf9b08e60c10ee71ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee37ece7e2e641f5b6ff23031141db4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ablated_results_hub_spoke_all = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257, 12649],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts= {\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the effect of ablation of the hub alone both spokes alone hub and both spokes together and both spokes together I hope hub and spokes will be more effective than any of these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.62\n"
     ]
    }
   ],
   "source": [
    "print(normal_results[\"numeric_accuracy_strict\"])\n",
    "print(normal_results[\"numeric_accuracy_lenient\"])\n",
    "print(normal_results[\"special_accuracy_strict\"])\n",
    "print(normal_results[\"special_accuracy_lenient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.74\n",
      "0.0\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_hub[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_hub[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_hub[\"special_accuracy_strict\"])\n",
    "print(ablated_results_hub[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.84\n",
      "0.0\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_some[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_some[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_some[\"special_accuracy_strict\"])\n",
    "print(ablated_results_some[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9\n",
      "0.0\n",
      "0.64\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_all[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_all[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_all[\"special_accuracy_strict\"])\n",
    "print(ablated_results_all[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.88\n",
      "0.0\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(ablation_results_spokes[\"numeric_accuracy_strict\"])\n",
    "print(ablation_results_spokes[\"numeric_accuracy_lenient\"])\n",
    "print(ablation_results_spokes[\"special_accuracy_strict\"])\n",
    "print(ablation_results_spokes[\"special_accuracy_lenient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.86\n",
      "0.0\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "print(ablation_results_hub_spoke_some[\"numeric_accuracy_strict\"])\n",
    "print(ablation_results_hub_spoke_some[\"numeric_accuracy_lenient\"])\n",
    "print(ablation_results_hub_spoke_some[\"special_accuracy_strict\"])\n",
    "print(ablation_results_hub_spoke_some[\"special_accuracy_lenient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.94\n",
      "0.0\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_hub_spoke_all[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_hub_spoke_all[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_hub_spoke_all[\"special_accuracy_strict\"])\n",
    "print(ablated_results_hub_spoke_all[\"special_accuracy_lenient\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-cooccurence-DZTJ6ajw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
