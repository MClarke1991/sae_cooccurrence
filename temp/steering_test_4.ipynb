{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from num2words import num2words\n",
    "\n",
    "# from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE, ActivationsStore, HookedSAETransformer\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers.utils.logging import disable_progress_bar\n",
    "\n",
    "from sae_cooccurrence.utils.set_paths import get_git_root\n",
    "\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)\n",
    "\n",
    "git_root = get_git_root()\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8560abae60ac492d974c2f3e71096c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sae_lens/training/activations_store.py:245: UserWarning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# from transformer_lens import HookedTransformer\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(\"gemma-2-2b\", device=device)\n",
    "\n",
    "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
    "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
    "# We also return the feature sparsities which are stored in HF for convenience.\n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release=\"gemma-scope-2b-pt-res-canonical\",  # <- Release name\n",
    "    sae_id=\"layer_12/width_16k/canonical\",  # <- SAE id (not always a hook point!)\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "activation_store = ActivationsStore.from_sae(\n",
    "    model=model,\n",
    "    sae=sae,\n",
    "    streaming=True,\n",
    "    # fairly conservative parameters here so can use same for larger\n",
    "    # models without running out of memory.\n",
    "    store_batch_size_prompts=8,\n",
    "    train_batch_size_tokens=4096,\n",
    "    n_batches_in_buffer=4,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens can be either black or white. Answer each question with a single word:\n",
      "- Use number words between 'one' and 'ten' for specific quantities\n",
      "- Use 'zero' for no tokens\n",
      "- Use 'all' for all tokens\n",
      "- Use 'some' for partial quantities\n",
      "Never use digits (1, 2, 3, etc.).\n",
      "\n",
      "For example:\n",
      "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
      "A: five\n",
      "\n",
      "Q: I have five tokens, and all of them are black. How many of my tokens are white?\n",
      "A: zero\n",
      "\n",
      "Q: I have eight tokens, and some of them are black. How many of my tokens are white?\n",
      "A: some\n",
      "\n",
      "Training Questions:\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have eight tokens, and some of them are white. How many of my tokens are black?\n",
      "A: some\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have three tokens, and all of them are white. How many of my tokens are black?\n",
      "A: none\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have six tokens, and some of them are white. How many of my tokens are black?\n",
      "A: some\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have five tokens, and all of them are black. How many of my tokens are white?\n",
      "A: none\n",
      "\n",
      "\n",
      "# Basic cases - all/none\n",
      "Q: I have nine tokens, and none of them are white. How many of my tokens are black?\n",
      "A: all\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have four tokens, and three of them are white. How many of my tokens are black?\n",
      "A: one\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have five tokens, and two of them are black. How many of my tokens are white?\n",
      "A: three\n",
      "\n",
      "\n",
      "# Cases with specific numbers\n",
      "Q: I have three tokens, and one of them are black. How many of my tokens are white?\n",
      "A: two\n",
      "\n",
      "\n",
      "# Cases with 'some'\n",
      "Q: I have seven tokens, and some of them are white. How many of my tokens are black?\n",
      "A: some\n",
      "\n",
      "\n",
      "# Cases with 'some'\n",
      "Q: I have four tokens, and none of them are black. How many of my tokens are white?\n",
      "A: all\n",
      "\n",
      "\n",
      "# Zero cases\n",
      "Q: I have six tokens, and all of them are black. How many of my tokens are white?\n",
      "A: zero\n",
      "\n",
      "\n",
      "# Zero cases\n",
      "Q: I have three tokens, and all of them are black. How many of my tokens are white?\n",
      "A: zero\n",
      "\n",
      "\n",
      "Test Question:\n",
      "Q: I have eight tokens, and six of them are white. How many of my tokens are black?\n",
      "\n",
      "Expected Answer:\n",
      "A: two\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from num2words import num2words\n",
    "\n",
    "\n",
    "class TokenQuestionGenerator:\n",
    "    def __init__(self):\n",
    "        self.colors = [\"black\", \"white\"]\n",
    "        self.special_cases = {\"some\": \"some\", \"all\": \"none\", \"none\": \"all\"}\n",
    "        self.sections = [\"basic\", \"numeric\", \"special\", \"zero\"]\n",
    "\n",
    "    def _number_to_words(self, n: int) -> str:\n",
    "        \"\"\"Convert a number to words.\"\"\"\n",
    "        return num2words(n)\n",
    "\n",
    "    def _questions_are_equivalent(self, q1: str, q2: str) -> bool:\n",
    "        \"\"\"Compare two questions to check if they are functionally equivalent.\"\"\"\n",
    "        # Extract key parts for comparison\n",
    "        q1_parts = [\n",
    "            p.lower()\n",
    "            for p in q1.split()\n",
    "            if p.lower()\n",
    "            not in [\n",
    "                \"q:\",\n",
    "                \"a:\",\n",
    "                \"and\",\n",
    "                \"are\",\n",
    "                \"of\",\n",
    "                \"them\",\n",
    "                \"my\",\n",
    "                \"tokens\",\n",
    "                \"have\",\n",
    "                \"how\",\n",
    "                \"many\",\n",
    "            ]\n",
    "        ]\n",
    "        q2_parts = [\n",
    "            p.lower()\n",
    "            for p in q2.split()\n",
    "            if p.lower()\n",
    "            not in [\n",
    "                \"q:\",\n",
    "                \"a:\",\n",
    "                \"and\",\n",
    "                \"are\",\n",
    "                \"of\",\n",
    "                \"them\",\n",
    "                \"my\",\n",
    "                \"tokens\",\n",
    "                \"have\",\n",
    "                \"how\",\n",
    "                \"many\",\n",
    "            ]\n",
    "        ]\n",
    "        return q1_parts == q2_parts\n",
    "\n",
    "    def generate_zero_case_question(self) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question where one color has zero tokens.\"\"\"\n",
    "        n_total = random.randint(2, 10)\n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"all of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = \"zero\"\n",
    "        return question, answer\n",
    "\n",
    "    def generate_numeric_question(\n",
    "        self, force_complementary: bool = False\n",
    "    ) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question with numeric values.\"\"\"\n",
    "        n_total = random.randint(3, 10)  # Minimum 3 tokens for more interesting cases\n",
    "        if force_complementary:\n",
    "            # Generate numbers that sum to interesting complements\n",
    "            n_color_tokens = random.randint(\n",
    "                1, n_total - 1\n",
    "            )  # Ensure at least 1 token of each color\n",
    "        else:\n",
    "            n_color_tokens = random.randint(0, n_total)\n",
    "\n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"{self._number_to_words(n_color_tokens)} of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = self._number_to_words(n_total - n_color_tokens)\n",
    "        return question, answer\n",
    "\n",
    "    def generate_special_case_question(self) -> tuple[str, str]:\n",
    "        \"\"\"Generate a question with special quantifiers (some, all, none).\"\"\"\n",
    "        special_type = random.choice(list(self.special_cases.keys()))\n",
    "        colors = random.sample(self.colors, 2)\n",
    "        held_color, test_color = colors\n",
    "        n_total = random.randint(3, 10)\n",
    "\n",
    "        question = (\n",
    "            f\"Q: I have {self._number_to_words(n_total)} tokens, and \"\n",
    "            f\"{special_type} of them are {held_color}. \"\n",
    "            f\"How many of my tokens are {test_color}?\"\n",
    "        )\n",
    "        answer = self.special_cases[special_type]\n",
    "        return question, answer\n",
    "\n",
    "    def generate_test_question(\n",
    "        self, force_numeric: bool | None = None, force_special: bool | None = None\n",
    "    ) -> tuple[str, str]:\n",
    "        \"\"\"Generate a test question.\"\"\"\n",
    "        if force_numeric and force_special:\n",
    "            raise ValueError(\"Cannot force both numeric and special case\")\n",
    "\n",
    "        if force_numeric:\n",
    "            return self.generate_numeric_question(force_complementary=True)\n",
    "        elif force_special:\n",
    "            return self.generate_special_case_question()\n",
    "        else:\n",
    "            generators = [\n",
    "                self.generate_numeric_question,\n",
    "                self.generate_special_case_question,\n",
    "                self.generate_zero_case_question,\n",
    "            ]\n",
    "            return random.choice(generators)()\n",
    "\n",
    "    def generate_training_set(self, section_counts: dict) -> list[tuple[str, str, str]]:\n",
    "        \"\"\"Generate a structured training set with sections.\"\"\"\n",
    "        training_set = []\n",
    "\n",
    "        # Basic cases (all/none)\n",
    "        for _ in range(section_counts.get(\"basic\", 0)):\n",
    "            q, a = self.generate_special_case_question()\n",
    "            training_set.append((\"# Basic cases - all/none\", q, a))\n",
    "\n",
    "        # Numeric cases with specific complementary numbers\n",
    "        for _ in range(section_counts.get(\"numeric\", 0)):\n",
    "            q, a = self.generate_numeric_question(force_complementary=True)\n",
    "            training_set.append((\"# Cases with specific numbers\", q, a))\n",
    "\n",
    "        # Special cases (some)\n",
    "        for _ in range(section_counts.get(\"special\", 0)):\n",
    "            q, a = self.generate_special_case_question()\n",
    "            training_set.append((\"# Cases with 'some'\", q, a))\n",
    "\n",
    "        # Zero cases\n",
    "        for _ in range(section_counts.get(\"zero\", 0)):\n",
    "            q, a = self.generate_zero_case_question()\n",
    "            training_set.append((\"# Zero cases\", q, a))\n",
    "\n",
    "        return training_set\n",
    "\n",
    "\n",
    "def generate_training_and_test(\n",
    "    section_counts: dict = {\n",
    "        \"basic\": 2,  # all/none cases\n",
    "        \"numeric\": 3,  # specific number cases\n",
    "        \"special\": 2,  # 'some' cases\n",
    "        \"zero\": 2,  # explicit zero cases\n",
    "    },\n",
    "    force_test_type: str | None = None,\n",
    "    max_attempts: int = 100,\n",
    ") -> dict:\n",
    "    \"\"\"Generate a structured training set and test question.\"\"\"\n",
    "    generator = TokenQuestionGenerator()\n",
    "\n",
    "    # Generate test question\n",
    "    force_numeric = True if force_test_type == \"numeric\" else None\n",
    "    force_special = True if force_test_type == \"special\" else None\n",
    "    test_question, test_answer = generator.generate_test_question(\n",
    "        force_numeric=force_numeric, force_special=force_special\n",
    "    )\n",
    "\n",
    "    # Generate training set with sections\n",
    "    training_set = []\n",
    "    attempts = 0\n",
    "\n",
    "    while len(training_set) < sum(section_counts.values()) and attempts < max_attempts:\n",
    "        current_set = generator.generate_training_set(section_counts)\n",
    "\n",
    "        # Filter out any questions that match the test question\n",
    "        filtered_set = [\n",
    "            (section, q, a)\n",
    "            for section, q, a in current_set\n",
    "            if not generator._questions_are_equivalent(q, test_question)\n",
    "        ]\n",
    "\n",
    "        if len(filtered_set) == sum(section_counts.values()):\n",
    "            training_set = filtered_set\n",
    "            break\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    if attempts >= max_attempts:\n",
    "        raise RuntimeError(\n",
    "            \"Failed to generate unique training set after maximum attempts\"\n",
    "        )\n",
    "\n",
    "    # Format the introduction with explicit instructions for single-word answers\n",
    "    introduction = \"\"\"\n",
    "Tokens can be either black or white. Answer each question with a single word:\n",
    "- Use number words between 'one' and 'ten' for specific quantities\n",
    "- Use 'zero' for no tokens\n",
    "- Use 'all' for all tokens\n",
    "- Use 'some' for partial quantities\n",
    "Never use digits (1, 2, 3, etc.).\n",
    "\n",
    "For example:\n",
    "Q: I have ten tokens, and five of them are black. How many of my tokens are white?\n",
    "A: five\n",
    "\n",
    "Q: I have five tokens, and all of them are black. How many of my tokens are white?\n",
    "A: zero\n",
    "\n",
    "Q: I have eight tokens, and some of them are black. How many of my tokens are white?\n",
    "A: some\n",
    "\"\"\"\n",
    "\n",
    "    return {\n",
    "        \"introduction\": introduction.strip(),\n",
    "        \"training_questions\": training_set,\n",
    "        \"test_question\": test_question,\n",
    "        \"test_answer\": test_answer,\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Custom section counts\n",
    "    section_counts = {\n",
    "        \"basic\": 5,  # all/none cases\n",
    "        \"numeric\": 3,  # specific number cases\n",
    "        \"special\": 2,  # 'some' cases\n",
    "        \"zero\": 2,  # explicit zero cases\n",
    "    }\n",
    "\n",
    "    result = generate_training_and_test(\n",
    "        section_counts=section_counts,\n",
    "        force_test_type=\"numeric\",  # Can be 'numeric', 'special', or None\n",
    "    )\n",
    "\n",
    "    print(result[\"introduction\"])\n",
    "    print(\"\\nTraining Questions:\")\n",
    "    for section, q, a in result[\"training_questions\"]:\n",
    "        if section:\n",
    "            print(f\"\\n{section}\")\n",
    "        print(f\"{q}\\nA: {a}\\n\")\n",
    "    print(\"\\nTest Question:\")\n",
    "    print(result[\"test_question\"])\n",
    "    print(\"\\nExpected Answer:\")\n",
    "    print(f\"A: {result['test_answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def find_max_activation(model, sae, activation_store, feature_idx, num_batches=100):\n",
    "    \"\"\"\n",
    "    Find the maximum activation for a given feature index. This is useful for\n",
    "    calibrating the right amount of the feature to add.\n",
    "    \"\"\"\n",
    "    max_activation = 0.0\n",
    "\n",
    "    pbar = tqdm(range(num_batches))\n",
    "    for _ in pbar:\n",
    "        tokens = activation_store.get_batch_tokens()\n",
    "\n",
    "        _, cache = model.run_with_cache(\n",
    "            tokens,\n",
    "            stop_at_layer=sae.cfg.hook_layer + 1,\n",
    "            names_filter=[sae.cfg.hook_name],\n",
    "        )\n",
    "        sae_in = cache[sae.cfg.hook_name]\n",
    "        feature_acts = sae.encode(sae_in).squeeze()\n",
    "\n",
    "        feature_acts = feature_acts.flatten(0, 1)\n",
    "        batch_max_activation = feature_acts[:, feature_idx].max().item()\n",
    "        max_activation = max(max_activation, batch_max_activation)\n",
    "\n",
    "        pbar.set_description(f\"Max activation: {max_activation:.4f}\")\n",
    "\n",
    "    return max_activation\n",
    "\n",
    "\n",
    "def steering(activations, steering_strength=1.0, steering_vector=None, max_act=1.0):\n",
    "    # Note if the feature fires anyway, we'd be adding to that here.\n",
    "    return activations + max_act * steering_strength * steering_vector\n",
    "\n",
    "\n",
    "def generate_with_steering(\n",
    "    model,\n",
    "    sae,\n",
    "    prompt,\n",
    "    steering_feature,\n",
    "    max_act,\n",
    "    steering_strength=1.0,\n",
    "    max_new_tokens=95,\n",
    "):\n",
    "    input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "\n",
    "    steering_vector = sae.W_dec[steering_feature].to(model.cfg.device)\n",
    "\n",
    "    steering_hook = partial(\n",
    "        steering,\n",
    "        steering_vector=steering_vector,\n",
    "        steering_strength=steering_strength,\n",
    "        max_act=max_act,\n",
    "    )\n",
    "\n",
    "    # standard transformerlens syntax for a hook context for generation\n",
    "    with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            stop_at_eos=False if device == \"mps\" else True,\n",
    "            prepend_bos=sae.cfg.prepend_bos,\n",
    "        )\n",
    "\n",
    "    return model.tokenizer.decode(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_steering(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    feature_to_steer: int | None = None,\n",
    "    steering_strength: float = 1.0,\n",
    "    max_act: float = 60.0,\n",
    "    n_numeric: int = 10,\n",
    "    n_special: int = 10,\n",
    "    max_new_tokens: int = 2,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Test model accuracy on token counting tasks with optional feature steering.\n",
    "\n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        sae: The sparse autoencoder\n",
    "        feature_to_steer: Feature index to steer, or None for no steering\n",
    "        steering_strength: Strength of steering (default 1.0)\n",
    "        max_act: Maximum activation for the steered feature\n",
    "        n_numeric: Number of numeric test questions\n",
    "        n_special: Number of special test questions\n",
    "        max_new_tokens: Maximum tokens to generate for each answer\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing accuracy metrics and test results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"numeric_correct\": 0,\n",
    "        \"special_correct\": 0,\n",
    "        \"numeric_tests\": [],\n",
    "        \"special_tests\": [],\n",
    "    }\n",
    "\n",
    "    for test_type in [\"numeric\", \"special\"]:\n",
    "        n_tests = n_numeric if test_type == \"numeric\" else n_special\n",
    "        for _ in range(n_tests):\n",
    "            test_data = generate_training_and_test(\n",
    "                num_training_numeric=40,\n",
    "                num_training_special=20,\n",
    "                force_test_type=test_type,\n",
    "            )\n",
    "\n",
    "            prompt = (\n",
    "                test_data[\"introduction\"]\n",
    "                + \"\\n\\n\"\n",
    "                + \"\\n\\n\".join(\n",
    "                    f\"{q}\\n{a}\\n{label}\"\n",
    "                    for q, a, label in test_data[\"training_questions\"]\n",
    "                )\n",
    "                + f\"\\n\\n{test_data['test_question']}\\nA: \"\n",
    "            )\n",
    "\n",
    "            if feature_to_steer is not None:\n",
    "                generated = generate_with_steering(\n",
    "                    model,\n",
    "                    sae,\n",
    "                    prompt,\n",
    "                    feature_to_steer,\n",
    "                    max_act,\n",
    "                    steering_strength=steering_strength,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                )\n",
    "            else:\n",
    "                # Convert prompt to tokens first\n",
    "                input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "                output = model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    # temperature=0.7,\n",
    "                    # top_p=0.9,\n",
    "                    stop_at_eos=False if device == \"mps\" else True,\n",
    "                    prepend_bos=sae.cfg.prepend_bos,\n",
    "                )\n",
    "                generated = model.tokenizer.decode(output[0])\n",
    "\n",
    "            test_result = {\n",
    "                \"prompt\": prompt,\n",
    "                \"expected\": test_data[\"test_answer\"],\n",
    "                \"generated\": generated,\n",
    "                \"correct\": test_data[\"test_answer\"] in generated,\n",
    "            }\n",
    "\n",
    "            if test_type == \"numeric\":\n",
    "                results[\"numeric_tests\"].append(test_result)\n",
    "                if test_result[\"correct\"]:\n",
    "                    results[\"numeric_correct\"] += 1\n",
    "            else:\n",
    "                results[\"special_tests\"].append(test_result)\n",
    "                if test_result[\"correct\"]:\n",
    "                    results[\"special_correct\"] += 1\n",
    "\n",
    "    # Calculate accuracies\n",
    "    results[\"numeric_accuracy\"] = results[\"numeric_correct\"] / n_numeric\n",
    "    results[\"special_accuracy\"] = results[\"special_correct\"] / n_special\n",
    "    results[\"total_accuracy\"] = (\n",
    "        results[\"numeric_correct\"] + results[\"special_correct\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Test without steering\n",
    "#     normal_results = evaluate_model_with_steering(model, sae)\n",
    "#     print(\"\\nResults without steering:\")\n",
    "#     print(f\"Numeric accuracy: {normal_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {normal_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {normal_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results:\")\n",
    "#     for i, test in enumerate(normal_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results:\")\n",
    "#     for i, test in enumerate(normal_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     # Test with feature steering\n",
    "#     feature_to_steer = 12257  # Replace with your feature of interest\n",
    "#     steering_strength = 0.0\n",
    "#     steered_results = evaluate_model_with_steering(\n",
    "#         model,\n",
    "#         sae,\n",
    "#         feature_to_steer=feature_to_steer,\n",
    "#         steering_strength=steering_strength,\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"\\nResults with feature {feature_to_steer} steered (strength {steering_strength}):\"\n",
    "#     )\n",
    "#     print(f\"Numeric accuracy: {steered_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {steered_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {steered_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     # Test with feature steering\n",
    "#     feature_to_steer = 15441  # Replace with your feature of interest\n",
    "#     steering_strength = 0.0\n",
    "#     steered_results = evaluate_model_with_steering(\n",
    "#         model,\n",
    "#         sae,\n",
    "#         feature_to_steer=feature_to_steer,\n",
    "#         steering_strength=steering_strength,\n",
    "#     )\n",
    "#     print(\n",
    "#         f\"\\nResults with feature {feature_to_steer} steered (strength {steering_strength}):\"\n",
    "#     )\n",
    "#     print(f\"Numeric accuracy: {steered_results['numeric_accuracy']:.2%}\")\n",
    "#     print(f\"Special accuracy: {steered_results['special_accuracy']:.2%}\")\n",
    "#     print(f\"Total accuracy: {steered_results['total_accuracy']:.2%}\")\n",
    "\n",
    "#     print(\"\\nNumeric test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"numeric_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")\n",
    "\n",
    "#     print(\"\\nSpecial test results (with steering):\")\n",
    "#     for i, test in enumerate(steered_results[\"special_tests\"], 1):\n",
    "#         print(f\"\\nTest {i}:\")\n",
    "#         question = test[\"prompt\"].split(\"A: \")[0].splitlines()[-1]\n",
    "#         print(f\"Question: {question}\")\n",
    "#         print(f\"Expected: {test['expected']}\")\n",
    "#         print(f\"Generated: {test['generated']}\")\n",
    "#         print(f\"Correct: {test['correct']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_intervention(\n",
    "    model: HookedSAETransformer,\n",
    "    sae: SAE,\n",
    "    feature_ids: int | list[int] | None = None,\n",
    "    intervention_type: str = \"none\",  # \"none\", \"steering\", or \"ablation\"\n",
    "    steering_strength: float = 1.0,\n",
    "    max_act: float = 60.0,\n",
    "    n_numeric: int = 10,\n",
    "    n_special: int = 10,\n",
    "    max_new_tokens: int = 1,\n",
    "    temperature: float = 0.0,\n",
    "    top_p: float = 0.9,\n",
    "    section_counts: dict | None = None,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Test model accuracy on token counting tasks with optional feature steering or ablation.\n",
    "    Lenient scoring now accepts numeric answers for 'all' cases.\n",
    "    \"\"\"\n",
    "    if section_counts is None:\n",
    "        section_counts = {\n",
    "            \"basic\": 2,  # all/none cases\n",
    "            \"numeric\": 3,  # specific number cases\n",
    "            \"special\": 2,  # 'some' cases\n",
    "            \"zero\": 2,  # explicit zero cases\n",
    "        }\n",
    "\n",
    "    results = {\n",
    "        \"numeric_correct_strict\": 0,\n",
    "        \"numeric_correct_lenient\": 0,\n",
    "        \"special_correct_strict\": 0,\n",
    "        \"special_correct_lenient\": 0,\n",
    "        \"numeric_tests\": [],\n",
    "        \"special_tests\": [],\n",
    "    }\n",
    "\n",
    "    def convert_words_to_digits(text: str) -> str:\n",
    "        \"\"\"Convert number words to digits in the text.\"\"\"\n",
    "        word_to_digit = {\n",
    "            \"zero\": \"0\",\n",
    "            \"none\": \"0\",\n",
    "            \"one\": \"1\",\n",
    "            \"two\": \"2\",\n",
    "            \"three\": \"3\",\n",
    "            \"four\": \"4\",\n",
    "            \"five\": \"5\",\n",
    "            \"six\": \"6\",\n",
    "            \"seven\": \"7\",\n",
    "            \"eight\": \"8\",\n",
    "            \"nine\": \"9\",\n",
    "            \"ten\": \"10\",\n",
    "        }\n",
    "        for word, digit in word_to_digit.items():\n",
    "            text = text.replace(word, digit)\n",
    "        return text\n",
    "\n",
    "    def check_answer_lenient(generated: str, expected: str, question: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if answer is correct under lenient scoring rules.\n",
    "\n",
    "        Args:\n",
    "            generated: Generated answer text\n",
    "            expected: Expected answer text\n",
    "            question: Original question text (needed to extract total token count)\n",
    "\n",
    "        Returns:\n",
    "            bool: Whether the answer is correct under lenient scoring\n",
    "        \"\"\"\n",
    "        # Convert both to lowercase for comparison\n",
    "        generated = generated.lower()\n",
    "        expected = expected.lower()\n",
    "\n",
    "        # First check if it's an exact match after converting words to digits\n",
    "        generated_digits = convert_words_to_digits(generated)\n",
    "        expected_digits = convert_words_to_digits(expected)\n",
    "\n",
    "        if expected_digits in generated_digits:\n",
    "            return True\n",
    "\n",
    "        # Check if this is an \"all of them are\" case\n",
    "        if \"all of them are\" in expected:\n",
    "            # Extract the total number from the question\n",
    "            question_words = question.lower().split()\n",
    "            try:\n",
    "                # Find the word after \"have\" in the question\n",
    "                have_idx = question_words.index(\"have\")\n",
    "                total_tokens = convert_words_to_digits(question_words[have_idx + 1])\n",
    "\n",
    "                # Check if the generated answer contains this number\n",
    "                # Allow both \"N of them\" and just \"N\"\n",
    "                return (\n",
    "                    total_tokens in generated_digits\n",
    "                    or f\"{total_tokens} of them\" in generated_digits\n",
    "                )\n",
    "            except (ValueError, IndexError):\n",
    "                return False\n",
    "\n",
    "        return False\n",
    "\n",
    "    # Convert single feature_id to list for consistency\n",
    "    if isinstance(feature_ids, int):\n",
    "        feature_ids = [feature_ids]\n",
    "\n",
    "    def ablate_feature_hook(feature_activations, hook=None, feature_ids=None):  # noqa: ARG001\n",
    "        feature_activations[:, :, feature_ids] = 0\n",
    "        return feature_activations\n",
    "\n",
    "    for test_type in tqdm([\"numeric\", \"special\"], desc=\"Testing types\"):\n",
    "        n_tests = n_numeric if test_type == \"numeric\" else n_special\n",
    "        for _ in tqdm(range(n_tests), desc=f\"Testing {test_type}\"):\n",
    "            # Use new structured prompt generator\n",
    "            test_data = generate_training_and_test(\n",
    "                section_counts=section_counts,\n",
    "                force_test_type=test_type,\n",
    "            )\n",
    "\n",
    "            # Construct prompt with sections\n",
    "            prompt_parts = [test_data[\"introduction\"]]\n",
    "\n",
    "            # Group questions by section\n",
    "            sections = {}\n",
    "            for section, q, a in test_data[\"training_questions\"]:\n",
    "                if section not in sections:\n",
    "                    sections[section] = []\n",
    "                sections[section].append((q, a))\n",
    "\n",
    "            # Add each section with its header\n",
    "            for section, questions in sections.items():\n",
    "                prompt_parts.append(f\"\\n\\n{section}\")\n",
    "                for q, a in questions:\n",
    "                    prompt_parts.append(f\"{q}\\n{a}\")\n",
    "\n",
    "            # Add test question\n",
    "            prompt_parts.append(f\"\\n\\n{test_data['test_question']}\\nA: \")\n",
    "\n",
    "            prompt = \"\\n\\n\".join(prompt_parts)\n",
    "\n",
    "            # Convert prompt to tokens\n",
    "            input_ids = model.to_tokens(prompt, prepend_bos=sae.cfg.prepend_bos)\n",
    "\n",
    "            if intervention_type == \"none\" or feature_ids is None:\n",
    "                output = model.generate(\n",
    "                    input_ids,\n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    temperature=temperature,\n",
    "                    top_p=top_p,\n",
    "                    stop_at_eos=False if device == \"mps\" else True,\n",
    "                    prepend_bos=sae.cfg.prepend_bos,\n",
    "                )\n",
    "\n",
    "            elif intervention_type == \"steering\":\n",
    "                steering_vector = sae.W_dec[feature_ids[0]].to(model.cfg.device)\n",
    "                steering_hook = partial(\n",
    "                    steering,\n",
    "                    steering_vector=steering_vector,\n",
    "                    steering_strength=steering_strength,\n",
    "                    max_act=max_act,\n",
    "                )\n",
    "\n",
    "                with model.hooks(fwd_hooks=[(sae.cfg.hook_name, steering_hook)]):\n",
    "                    output = model.generate(\n",
    "                        input_ids,\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        temperature=temperature,\n",
    "                        top_p=top_p,\n",
    "                        stop_at_eos=False if device == \"mps\" else True,\n",
    "                        prepend_bos=sae.cfg.prepend_bos,\n",
    "                    )\n",
    "\n",
    "            elif intervention_type == \"ablation\":\n",
    "                ablation_hook = partial(ablate_feature_hook, feature_ids=feature_ids)\n",
    "                model.add_sae(sae)\n",
    "                hook_point = sae.cfg.hook_name + \".hook_sae_acts_post\"\n",
    "                if not model.is_hook_point_valid(hook_point):  # assuming such a method exists\n",
    "                    raise ValueError(f\"Invalid hook point: {hook_point}\")\n",
    "\n",
    "                with model.hooks(fwd_hooks=[(hook_point, ablation_hook)]):\n",
    "                    output = model.generate(\n",
    "                        input_ids,\n",
    "                        max_new_tokens=max_new_tokens,\n",
    "                        top_p=top_p,\n",
    "                        temperature=temperature,\n",
    "                        stop_at_eos=False if device == \"mps\" else True,\n",
    "                        prepend_bos=sae.cfg.prepend_bos,\n",
    "                    )\n",
    "\n",
    "                model.reset_hooks()\n",
    "                model.reset_saes()\n",
    "\n",
    "            generated = model.tokenizer.decode(output[0])  # type: ignore\n",
    "            generated_answer = generated.split(\"A: \")[-1].strip()\n",
    "            expected_answer = test_data[\"test_answer\"].replace(\"A: \", \"\").strip()\n",
    "            test_question = test_data[\"test_question\"].split(\"\\n\")[0].strip()\n",
    "\n",
    "            test_result = {\n",
    "                \"prompt\": prompt,\n",
    "                \"expected\": expected_answer,\n",
    "                \"generated\": generated_answer,\n",
    "                \"correct_strict\": expected_answer in generated_answer,\n",
    "                \"correct_lenient\": check_answer_lenient(\n",
    "                    generated_answer, expected_answer, test_question\n",
    "                ),\n",
    "                \"section_counts\": section_counts,\n",
    "            }\n",
    "\n",
    "            if test_type == \"numeric\":\n",
    "                results[\"numeric_tests\"].append(test_result)\n",
    "                if test_result[\"correct_strict\"]:\n",
    "                    results[\"numeric_correct_strict\"] += 1\n",
    "                if test_result[\"correct_lenient\"]:\n",
    "                    results[\"numeric_correct_lenient\"] += 1\n",
    "            else:\n",
    "                results[\"special_tests\"].append(test_result)\n",
    "                if test_result[\"correct_strict\"]:\n",
    "                    results[\"special_correct_strict\"] += 1\n",
    "                if test_result[\"correct_lenient\"]:\n",
    "                    results[\"special_correct_lenient\"] += 1\n",
    "\n",
    "    # Calculate accuracies\n",
    "    results[\"numeric_accuracy_strict\"] = results[\"numeric_correct_strict\"] / n_numeric\n",
    "    results[\"numeric_accuracy_lenient\"] = results[\"numeric_correct_lenient\"] / n_numeric\n",
    "    results[\"special_accuracy_strict\"] = results[\"special_correct_strict\"] / n_special\n",
    "    results[\"special_accuracy_lenient\"] = results[\"special_correct_lenient\"] / n_special\n",
    "    results[\"total_accuracy_strict\"] = (\n",
    "        results[\"numeric_correct_strict\"] + results[\"special_correct_strict\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "    results[\"total_accuracy_lenient\"] = (\n",
    "        results[\"numeric_correct_lenient\"] + results[\"special_correct_lenient\"]\n",
    "    ) / (n_numeric + n_special)\n",
    "\n",
    "    # Add section configuration to results\n",
    "    results[\"section_counts\"] = section_counts\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8b652d0c2749c987ffa49694985f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6154b640c592480e98d566b1f89f98e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0622e45d734023a2e2a34e6c6a09cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f3ae4d117349ab95885f331edfcebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98edb3010674e94833582a636b1460a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normal_results = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    intervention_type=\"none\",\n",
    "    n_numeric=1,\n",
    "    n_special=1,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 0, \"special\": 20, \"zero\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Answer each question with a single word:\\n- Use number words between 'one' and 'ten' for specific quantities\\n- Use 'zero' for no tokens\\n- Use 'all' for all tokens\\n- Use 'some' for partial quantities\\nNever use digits (1, 2, 3, etc.).\\n\\nFor example:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: zero\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nnone\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nnone\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nsome\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nnone\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nnone\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nnone\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\n\\n\\nQ: I have ten tokens, and four of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'six',\n",
       "  'generated': '6',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 0, 'special': 20, 'zero': 0}}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results[\"numeric_tests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc3ff1eabff4329be00a8085baab355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c6655354da4d9594c2c6eb2fde08e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'HookedSAETransformer' object has no attribute 'is_hook_point_valid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ablated_results_hub \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_with_intervention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12257\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Can ablate multiple features\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervention_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mablation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_special\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 173\u001b[0m, in \u001b[0;36mevaluate_model_with_intervention\u001b[0;34m(model, sae, feature_ids, intervention_type, steering_strength, max_act, n_numeric, n_special, max_new_tokens, temperature, top_p, section_counts)\u001b[0m\n\u001b[1;32m    171\u001b[0m model\u001b[38;5;241m.\u001b[39madd_sae(sae)\n\u001b[1;32m    172\u001b[0m hook_point \u001b[38;5;241m=\u001b[39m sae\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mhook_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hook_sae_acts_post\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_hook_point_valid\u001b[49m(hook_point):  \u001b[38;5;66;03m# assuming such a method exists\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid hook point: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_point\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mhooks(fwd_hooks\u001b[38;5;241m=\u001b[39m[(hook_point, ablation_hook)]):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HookedSAETransformer' object has no attribute 'is_hook_point_valid'"
     ]
    }
   ],
   "source": [
    "ablated_results_hub = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=1,\n",
    "    n_special=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Answer each question with a single word:\\n- Use number words between 'one' and 'ten' for specific quantities\\n- Use 'zero' for no tokens\\n- Use 'all' for all tokens\\n- Use 'some' for partial quantities\\nNever use digits (1, 2, 3, etc.).\\n\\nFor example:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: zero\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nsome\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have five tokens, and one of them are white. How many of my tokens are black?\\nfour\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nfour\\n\\nQ: I have five tokens, and two of them are black. How many of my tokens are white?\\nthree\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nall\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nall\\n\\n\\n\\n# Zero cases\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nzero\\n\\nQ: I have two tokens, and all of them are black. How many of my tokens are white?\\nzero\\n\\n\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'none',\n",
       "  'generated': '0\\n\\nQ: I have',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 2, 'numeric': 3, 'special': 2, 'zero': 2}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ablated_results_hub[\"special_tests\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521abfe896f84e62b528a93fcbd2b6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8137788aa4f7475180cc5aa359398404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c614233d92c45d1b9e8d2b557d5a925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b8bea0ac5f478f8c130346686232d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e982ac1b274d1f88c38c6e1e910099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8032a5a42c34d5f9d3879ddf7e8c8f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ccf03d9a864f049bafc02ebbe17e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc7f703e132489f8a1977942de4d26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3037eb4730724568a0fae91d9698c08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8da1883b5a4b3ca4abab6d140b4865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1522a34e26f4934a18e884e5fc5632c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527ec79b5c164f4c800a279a76da59d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6630058d42ff4755a151a511b9850991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3033aaf693754f9d8e27ca34d70c4ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e3fb08b540418792499d67f538a6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc598e01d43248688676477a84404ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b7b0662f5c4b9bbd450de4a1cdb3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f59e67ff9c455d8de95bdf95776ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894c742127084cc690b270f6572be5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a9bebaa90b469583059683344b7244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5176d6774e04ac7984cde4ac987fe30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c4c2556a344d02b0318cbab23b3e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafa2c3352e34bbab17f6d2c7ff22134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f513efa55abc4bd0895c3b15f58e7d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7512bf5e11374f918b8123577e16ea50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b036f7fefd43c48e90144a8f866abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a3c2014bdb47bd8e7a4ec58c7a76ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcd2bf362534f95a343e0b946399036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000c0516e92c49ab9efe4e425424989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2068e0056b6847b48bc1ccfed50a2bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0e6cdee40f4e26add7311f2b09278e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8f7c5f944d42f58603427f67aeb9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af3780555344555918756e28929c4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0347a7af7695446594008e3c8c848323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1dc8c7b91e441291740189113b8798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76762b56581448d9af59601b52249a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f27c8472de48d18f49f4d044357e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4541647a68546b798980c581300bcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6bb510ff984b6bbf7e40169528cf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc3a0420fad4dbab6a5b99705229814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f468c00b5c34bd18b9769875b3de499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea675ab9c964ccc8bc1d598fa974c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71628c8212d74fb5b0b3a6af7a28ea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bd1c8a319a457b8d9db25801bdfb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab2c132eb994c6582a96e62136803eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf3c9a1b5cb4edfaa40c7f7318ac580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6abf7cfb30548e0a9486ca1caca33e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd8db0e833e64cd4aca1981d5249cbbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de95d3e4bbeb47a08de69209a1f0a974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8374c288badf4503a8631dbea8d26cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759070fa8f61439785403ff72c69a5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5304efb4948b41869b91f5674d5e246d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4611bd14ee4daa9c907a3b4d6d6eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ba835b9f7d4a13940bb92f35bf4e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec732a1d05544d7899974af815db85f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809d88c3a19f4025af5323b183020dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10681fc6f906485b89cce05d491c0e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8609b7ae8a4fb78d208d600c633f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686d6426e30a4958b863bda91066e418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8df839bf2ac44ff851d99f376b33b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dbeb9ee43d428ba3862c20570da2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e10b7c040e41288430d8ea7e012c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185d66c4ea1847fc889604551699e0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab35b8fb955943c18e12710db72f6b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3435f9de3d34476b6bc894453971001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1a84d4ff7c4259bbb2471123085876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffb772787414291aad59a11773f0fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100d83d2410c4f6a860ec9b354d3dd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb5d2adf7824002a742a8f8ca7e630e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d22a67da3499dbcae1fd9f13400bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9e40fef06f49c5b0b3ad2b3748a25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f369f2231e5248de9e015d3dfa8aed5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df056e18e07d4803a55d78ee022732cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08eba94b553442ca906b2892aaf4e279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e05a16eea6468682f3ffbe1cb5ed18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f42df0dfef543ca85eaa012873c9282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c0b3e7ead74eca9882ddf0d63c8e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2a6b957a9744279c97f36aa3b69b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc414f4313c54b2db977e527797f36c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a1d39f9ee84921ac6c98aff28676bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ac83ff820a49448f9d2d9ba50192de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6155c5b32eec4ff2900af8b8c6a000f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b43279d0a748c4a6d908ce21adf6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c60a7ff45f7439885cdf7cb6ec07fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c89c7cb75dd496d822f99a0c61c3b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfac4aced7034fb6a15c69ebac48fcc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4031663c34416995e8a9d5d91f8671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b5c3e9875d42ad82752fb56a0768ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12db534fd27d4595b91f2189b312f0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7cb925408c4736bf223bdd05911118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b15d418e1c34e6eb54d0e1822e7dd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888607c2d091435da29622bed8e968a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebea44c89da4efe8b72bdae2bc05d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbe44bf531a4292961ac097ebe92b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4be561955984a8d94d4f9f5dc97016a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd80508726142f7b12aa2de0751cb52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bee063257a48edb007a4fb7765b5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc67e4ba9fa44b2bf9c07f9d954d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bd26ffc5834f3d86f668dafa371507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479222a81d2a4c76b47a605b443e5b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f435a9a7ad2946fea943a163dab309be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d892d395cca41dda69a69cfc4cbec3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c3282690084c86a30eacf4bcc15aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test without intervention\n",
    "normal_results = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    intervention_type=\"none\",\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 20, \"zero\": 0},\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    ")\n",
    "\n",
    "# # Test with steering\n",
    "# steered_results = evaluate_model_with_intervention(\n",
    "#     model,\n",
    "#     sae,\n",
    "#     feature_ids=12257,\n",
    "#     intervention_type=\"steering\",\n",
    "#     steering_strength=1.0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(normal_results[\"numeric_accuracy_strict\"])\n",
    "print(normal_results[\"numeric_accuracy_lenient\"])\n",
    "print(normal_results[\"special_accuracy_strict\"])\n",
    "print(normal_results[\"special_accuracy_lenient\"])\n",
    "# Test with ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\nQ: I have seven tokens, and three of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'four of them are white',\n",
       "  'generated': '4 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and nine of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'one of them are black',\n",
       "  'generated': '1 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'two of them are black',\n",
       "  'generated': '2 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have eight tokens, and five of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'five of them are black',\n",
       "  'generated': '5 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have five tokens, and two of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'three of them are white',\n",
       "  'generated': '3 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and seven of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'two of them are black',\n",
       "  'generated': '2 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\nQ: I have nine tokens, and three of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'six of them are black',\n",
       "  'generated': '6 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'one of them are white',\n",
       "  'generated': '1 of them is white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'five of them are black',\n",
       "  'generated': '5 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have ten tokens, and two of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have four tokens, and three of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'one of them are white',\n",
       "  'generated': '1 of them is white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 3, 'numeric': 3, 'special': 3, 'zero': 0}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results[\"numeric_tests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have ten tokens, and three of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and one of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and seven of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and six of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have four tokens, and three of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have six tokens, and four of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and eight of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '1 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and seven of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have ten tokens, and one of them are black. How many of my tokens are white?\\nA: nine of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and two of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and six of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and eight of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and one of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have five tokens, and two of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'none of them are white',\n",
       "  'generated': '0 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and one of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have nine tokens, and two of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have eight tokens, and one of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have ten tokens, and seven of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and four of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have eight tokens, and six of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and three of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and three of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have eight tokens, and one of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'all of them are white',\n",
       "  'generated': '4 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and seven of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have three tokens, and two of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have ten tokens, and eight of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'some of them are white',\n",
       "  'generated': '1 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and five of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have eight tokens, and six of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and six of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and four of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have ten tokens, and four of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and one of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have three tokens, and two of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have ten tokens, and nine of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '0 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and two of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have ten tokens, and two of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have seven tokens, and three of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have five tokens, and one of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have ten tokens, and six of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and one of them are black. How many of my tokens are white?\\nA: eight of them are white\\n\\nQ: I have nine tokens, and eight of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'some of them are black',\n",
       "  'generated': '0 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and six of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have six tokens, and five of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and two of them are white. How many of my tokens are black?\\nA: seven of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and four of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have eight tokens, and three of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have four tokens, and two of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have seven tokens, and six of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and three of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have eight tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'some of them are white',\n",
       "  'generated': '5 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have four tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have ten tokens, and one of them are white. How many of my tokens are black?\\nA: nine of them are black\\n\\nQ: I have eight tokens, and one of them are black. How many of my tokens are white?\\nA: seven of them are white\\n\\nQ: I have nine tokens, and five of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have six tokens, and one of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have five tokens, and one of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and two of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have five tokens, and three of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and four of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have six tokens, and three of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have seven tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have eight tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'all of them are white',\n",
       "  'generated': '3 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have five tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have three tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have nine tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have six tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and four of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have six tokens, and two of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have six tokens, and five of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have eight tokens, and seven of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and six of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have nine tokens, and four of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nQ: I have seven tokens, and four of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have nine tokens, and eight of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and four of them are white. How many of my tokens are black?\\nA: five of them are black\\n\\nQ: I have four tokens, and one of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have ten tokens, and nine of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have four tokens, and one of them are black. How many of my tokens are white?\\nA: three of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have eight tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have nine tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have eight tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\n\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: \",\n",
       "  'expected': 'all of them are black',\n",
       "  'generated': '6 of them are black',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': False,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}},\n",
       " {'prompt': \"Tokens can be either black or white. Complete the following sentences using number words (one, two, three, etc.) never digits (1, 2, 3, etc.).\\nRemember:\\n- For 0, use 'zero' not '0'\\n- The total number of tokens equals the sum of black and white tokens\\n- Always write numbers as words (e.g., 'two' not '2')\\n\\nFor example, this is correct: \\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: five of them are white\\n\\nWhereas this is incorrect:\\nQ: I have ten tokens, and five of them are black. How many of my tokens are white?\\nA: 5 of them are white\\n\\n\\n\\n# Basic cases - all/none\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have six tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have five tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have four tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are white. How many of my tokens are black?\\nA: all of them are black\\n\\n\\n\\n# Cases with specific numbers\\n\\nQ: I have six tokens, and three of them are white. How many of my tokens are black?\\nA: three of them are black\\n\\nQ: I have four tokens, and three of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and five of them are black. How many of my tokens are white?\\nA: four of them are white\\n\\nQ: I have seven tokens, and three of them are white. How many of my tokens are black?\\nA: four of them are black\\n\\nQ: I have five tokens, and four of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have nine tokens, and one of them are white. How many of my tokens are black?\\nA: eight of them are black\\n\\nQ: I have seven tokens, and one of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have five tokens, and four of them are black. How many of my tokens are white?\\nA: one of them are white\\n\\nQ: I have eight tokens, and two of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have nine tokens, and three of them are black. How many of my tokens are white?\\nA: six of them are white\\n\\nQ: I have ten tokens, and four of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and one of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have seven tokens, and five of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have four tokens, and two of them are black. How many of my tokens are white?\\nA: two of them are white\\n\\nQ: I have three tokens, and two of them are white. How many of my tokens are black?\\nA: one of them are black\\n\\nQ: I have eight tokens, and two of them are white. How many of my tokens are black?\\nA: six of them are black\\n\\nQ: I have three tokens, and one of them are white. How many of my tokens are black?\\nA: two of them are black\\n\\n\\n\\n# Cases with 'some'\\n\\nQ: I have ten tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have ten tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have six tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have ten tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have seven tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have nine tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have seven tokens, and some of them are white. How many of my tokens are black?\\nA: some of them are black\\n\\nQ: I have nine tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have eight tokens, and all of them are black. How many of my tokens are white?\\nA: none of them are white\\n\\nQ: I have five tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have ten tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have five tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\nQ: I have seven tokens, and some of them are black. How many of my tokens are white?\\nA: some of them are white\\n\\nQ: I have three tokens, and none of them are black. How many of my tokens are white?\\nA: all of them are white\\n\\nQ: I have six tokens, and all of them are white. How many of my tokens are black?\\nA: none of them are black\\n\\n\\n\\nQ: I have ten tokens, and all of them are black. How many of my tokens are white?\\nA: \",\n",
       "  'expected': 'none of them are white',\n",
       "  'generated': '0 of them are white',\n",
       "  'correct_strict': False,\n",
       "  'correct_lenient': True,\n",
       "  'section_counts': {'basic': 20, 'numeric': 20, 'special': 20, 'zero': 0}}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_results[\"special_tests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b084bed6964c6aacb2291ee8ce336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc96dfa22854586a2a3115190e591fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76ea14fe4c64568a9c25a4935f077cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725aea008c54c009011a2147e261f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a778044599f494f95153955ae0d3725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b89f0b73e694f539b9cced00fbf33c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb55204939f94e5c8586e7eb901c90fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe4bdb5e848427bbad79535b75dbcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a37a246b73e4986b7d52cf215dc4c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ff3d3993dd45b7a646efe02e96c201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8b399b75d34ac0b94d88c209ac3e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e648e868fc9547e4a44b505217cfa116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6791fce8ff14f93805683df493a808d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922cc02fe6eb4fc2b2f9099c0400a163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfc9685eaa348f2b3292b7e6a977299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf0e651fed948e6bd1b8e280068a6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafac62a0dfe493e8d93e243454ead7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c149b7a04ef45d6abe757857b8af9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244aab1031c448b0aa33f9d127f068c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935ab40662204203973170104f31141d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2eebf4f9634838a9f972e44a459b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e760b6ea640dd8080d820a859a92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c83aa30756940d7b3544eeaa1939d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cb208e035d4db9880aff7243a33805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce5daa2852f4f039d7b8a4948fc7476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c70617fbf134fa4a78ea5f134285f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588c783ae67b465687e181efdc36d79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3b6c3af0f84c988afa45a0b56d110f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a74afec6e3e46d283a3d61382a8bc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee0dc9f46bb49f281f9dc3f7700c63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a3efd4e4704eee94cdc12958a18360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6861338b13c4cc99e7eb7d749211016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a051df1c83d94880826eb7af547868c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217c4c1e681d40dfa20688ecaf6ed827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab25da7821e44ce993d9af0d8bdcd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c597e78fd7041989949024aa7a65b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a72ed035e1340e99f73d5ac440de202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with ablation\n",
    "ablated_results_hub = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 0, \"special\": 20, \"zero\": 0},\n",
    ")\n",
    "\n",
    "ablated_results_some = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0},\n",
    ")\n",
    "\n",
    "ablated_results_all = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12649],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0},\n",
    ")\n",
    "\n",
    "ablation_results_spokes = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12649, 15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0},\n",
    ")\n",
    "\n",
    "ablation_results_hub_spoke_some = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257, 15441],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2882d4e5b494cccae858b3cb187c58b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing types:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db815ae79f64045a7f965b1f5be1132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing numeric:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c216a4426d4e7e9ae142808b833963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb40aff0546444bc8231a59c9532cb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450028fef5264a93adaa5fca8077a7f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a6fcfe0c0d43a9b45f3ee6b8fba5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b7a355509748acb1207ef92d2e0405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce549b4d10b44adb573b9e2d8acf74b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313fc60fea254f02ab5f9b1020261523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751d47e575704eca9707ee0dff53ace8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82fa665cc2246349ea093a98e57e77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabc8bf58b304993b5491394c4fc4557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd544b1cbed46699cc39fb8f9857c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing special:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b02b424e4a40fabb92d3eedba68e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ec104d61894117bddd40f067aa52e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c59d2c9079f4667bfa0684ea6a3eb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f1ed932e5545278f19c9c74cf50ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "064fe40b414a4ea99777428548130282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b04f637392043c4b5d1eb6ea95a2d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdb6cefd77448fbb9f9f0a1db7060e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a9cf450d4640ad986251a888bf3436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15771d141ded48b29db2ab5401120c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916c9c1acda94608b100943d2f2defb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ablated_results_hub_spoke_all = evaluate_model_with_intervention(\n",
    "    model,\n",
    "    sae,\n",
    "    feature_ids=[12257, 12649],  # Can ablate multiple features\n",
    "    intervention_type=\"ablation\",\n",
    "    n_numeric=50,\n",
    "    n_special=50,\n",
    "    section_counts={\"basic\": 20, \"numeric\": 20, \"special\": 0, \"zero\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the effect of ablation of the hub alone both spokes alone hub and both spokes together and both spokes together I hope hub and spokes will be more effective than any of these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_hub[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_hub[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_hub[\"special_accuracy_strict\"])\n",
    "print(ablated_results_hub[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9\n",
      "0.0\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_some[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_some[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_some[\"special_accuracy_strict\"])\n",
    "print(ablated_results_some[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_all[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_all[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_all[\"special_accuracy_strict\"])\n",
    "print(ablated_results_all[\"special_accuracy_lenient\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7\n",
      "0.0\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(ablation_results_spokes[\"numeric_accuracy_strict\"])\n",
    "print(ablation_results_spokes[\"numeric_accuracy_lenient\"])\n",
    "print(ablation_results_spokes[\"special_accuracy_strict\"])\n",
    "print(ablation_results_spokes[\"special_accuracy_lenient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.8\n",
      "0.0\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(ablation_results_hub_spoke_some[\"numeric_accuracy_strict\"])\n",
    "print(ablation_results_hub_spoke_some[\"numeric_accuracy_lenient\"])\n",
    "print(ablation_results_hub_spoke_some[\"special_accuracy_strict\"])\n",
    "print(ablation_results_hub_spoke_some[\"special_accuracy_lenient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.9\n",
      "0.0\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(ablated_results_hub_spoke_all[\"numeric_accuracy_strict\"])\n",
    "print(ablated_results_hub_spoke_all[\"numeric_accuracy_lenient\"])\n",
    "print(ablated_results_hub_spoke_all[\"special_accuracy_strict\"])\n",
    "print(ablated_results_hub_spoke_all[\"special_accuracy_lenient\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sae-cooccurence-DZTJ6ajw-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
